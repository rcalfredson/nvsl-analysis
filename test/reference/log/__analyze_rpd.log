# command: analyze.py -v '/media/Synology4/Yang Chen/2025-07-09/c[12]_*,/media/Synology4/Yang Chen/2025-07-08/c1*' -f 0-19 --ayc --rpd  [r16ba4fb8e25133fa7f24bb22ed5ed079eb07ec7b-M]

=== analyzing c1__2025-07-08__12-52-04.avi, fly 0 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=50,y=87,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=50,y=87,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=50,y=87,r=10)

processing trajectories...
exp fly
  lost: number frames: 7372 (6.82%), sequence length: avg: 3.5, max: 82
    during "on" (4023 frames, 2 per "on" cmd): 449 (11.16%)
    interpolating...
  long (>30) jumps: 6, suspicious: 0 (0.0%)
  total calculated rewards during training: 1540
    for zero-width border: 1701 (+10.5%)
      compared with actual ones: only calc.: 271, only actual: 581
  total control rewards during trainings 1, 2, and 3: 2694
yok fly
  lost: number frames: 19063 (17.63%) *** bad ***

total rewards training: 2015, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 77, 99, 117, 131, 124
  calc. exp: 49, 71, 66, 85, 84
  ctrl. exp: 193, 213, 232, 230, 226
    PI: -0.60, -0.50, -0.56, -0.46, -0.46
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 2
  actual: 122, 147, 158, 155, 154
  calc. exp: 75, 108, 121, 130, 134
  ctrl. exp: 229, 183, 148, 86, 68
    PI: -0.51, -0.26, -0.10, 0.20, 0.33
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 3
  actual: 86, 64, 79, 54, 81
  calc. exp: 84, 49, 68, 44, 75
  ctrl. exp: 90, 123, 81, 118, 113
    PI: -0.03, -0.43, -0.09, -0.46, -0.20
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 329.3, 221.8, 200.0, 170.3, 167.6
  yok: trajectory bad
training 2
  exp: 207.7, 136.2, 112.4, 92.0, 80.7
  yok: trajectory bad
training 3
  exp: 130.9, 195.0, 137.3, 226.5, 170.4
  yok: trajectory bad

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (21), 7, 10, 7, 11, 4
  calc. yok: trajectory bad
training 2
  calc. exp: (40), 26, 15, 13, 11, 12
  calc. yok: trajectory bad
training 3
  calc. exp: (33), 8, 5, 4, 8, 6
  calc. yok: trajectory bad

reward PI by post bucket (3 min)
training 1
  exp: -0.75, -0.63, -0.65, -0.54, -0.71
  yok: trajectory bad
training 2
  exp: -0.32, -0.46, -0.51, -0.50, -0.43
  yok: trajectory bad
training 3
  exp: -0.61, -0.70, -0.73, -0.60, -0.56
  yok: trajectory bad

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 7.4 vs. 5.7
  avg. distance between (exp): 328.3 vs. 217.5
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s]: 4.9 vs. 3.9
  avg. distance between (exp): 211.9 vs. 140.5
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s]: 7.1 vs. 8.2
  avg. distance between (exp): 141.1 vs. 170.6
  avg. distance between (yok): trajectory bad

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 9.9 vs. 9.0
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 427.8 vs. 353.9
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s] (exp): 7.1 vs. 5.8
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 294.4 vs. 188.7
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s] (exp): 7.5 vs. 10.3
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 148.8 vs. 204.4
  avg. distance between (yok): trajectory bad

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.9, 4.8, stop fraction: 0.47, 0.34
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 2
  exp: avg. speed bottom [mm/s]: 5.1, 3.5, stop fraction: 0.30, 0.42
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 3
  exp: avg. speed bottom [mm/s]: 3.9, 2.6, stop fraction: 0.31, 0.50
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad

rewards per distance traveled [m⁻¹]
training 1
  exp: 14.40, 25.26, 22.86, 30.17, 31.10
  yok: trajectory bad
training 2
  exp: 24.08, 43.54, 54.65, 74.49, 85.83
  yok: trajectory bad
training 3
  exp: 58.13, 31.19, 50.06, 27.87, 43.61
  yok: trajectory bad

=== analyzing c1__2025-07-08__12-52-04.avi, fly 1 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=196,y=87,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=196,y=87,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=196,y=87,r=10)

processing trajectories...
exp fly
  lost: number frames: 2547 (2.36%), sequence length: avg: 2.3, max: 20
    during "on" (4082 frames, 2 per "on" cmd): 280 (6.86%)
    interpolating...
  long (>30) jumps: 9, suspicious: 0 (0.0%)
  total calculated rewards during training: 1769
    for zero-width border: 1970 (+11.4%)
      compared with actual ones: only calc.: 323, only actual: 388
  total control rewards during trainings 1, 2, and 3: 2842
yok fly
  lost: number frames: 6189 (5.72%), sequence length: avg: 2.6, max: 106
    during "on" (4082 frames, 2 per "on" cmd): 305 (7.47%)
    interpolating...
  long (>30) jumps: 28, suspicious: 0 (0.0%)
  total calculated rewards during training: 1232
  total control rewards during trainings 1, 2, and 3: 2587

total rewards training: 2046, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 66, 119, 114, 128, 119
  calc. exp: 52, 87, 92, 106, 91
  ctrl. exp: 149, 219, 198, 225, 218
    PI: -0.48, -0.43, -0.37, -0.36, -0.41
  calc. yok: 38, 76, 56, 70, 45
  ctrl. yok: 116, 129, 108, 146, 118
    PI: -0.51, -0.26, -0.32, -0.35, -0.45
training 2
  actual: 163, 134, 133, 144, 144
  calc. exp: 127, 114, 111, 137, 138
  ctrl. exp: 255, 239, 197, 98, 147
    PI: -0.34, -0.35, -0.28, 0.17, -0.03
  calc. yok: 52, 60, 52, 59, 82
  ctrl. yok: 129, 121, 105, 138, 154
    PI: -0.43, -0.34, -0.34, -0.40, -0.31
training 3
  actual: 96, 104, 64, 61, 90
  calc. exp: 85, 99, 64, 54, 85
  ctrl. exp: 93, 80, 114, 110, 100
    PI: -0.04, 0.11, -0.28, -0.34, -0.08
  calc. yok: 100, 80, 89, 83, 69
  ctrl. yok: 198, 166, 172, 173, 154
    PI: -0.33, -0.35, -0.32, -0.35, -0.38

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 262.7, 186.8, 185.2, 186.6, 198.8
  yok: 348.1, 183.5, 185.7, 173.1, 179.0
training 2
  exp: 168.7, 175.4, 169.0, 98.1, 123.4
  yok: 135.8, 147.0, 144.8, 153.1, 138.9
training 3
  exp: 137.6, 101.5, 215.4, 197.9, 145.9
  yok: 267.4, 217.5, 389.6, 395.3, 277.9

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (38), 25, 6, 10, 11, 9
  calc. yok: (11), 6, 3, 7, 6, 9
training 2
  calc. exp: (34), 17, 11, 12, 10, 15
  calc. yok: (24), 14, 11, 7, 7, 7
training 3
  calc. exp: (29), 21, 24, 24, 6, 21
  calc. yok: (35), 12, 18, 9, 3, 6

reward PI by post bucket (3 min)
training 1
  exp: -0.15, -0.60, -0.38, -0.19, 0.12
  yok: -0.45, -0.68, -0.33, -0.40, -0.40
training 2
  exp: -0.23, -0.46, -0.38, -0.46, -0.23
  yok: -0.51, -0.44, -0.44, -0.33, -0.42
training 3
  exp: -0.05, 0.20, 0.04, -0.40, -0.12
  yok: -0.54, -0.42, -0.33, -0.79, -0.60

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 7.6 vs. 5.2
  avg. distance between (exp): 236.0 vs. 190.0
  avg. distance between (yok): 297.6 vs. 188.7
training 2
  avg. time between [s]: 3.5 vs. 4.1
  avg. distance between (exp): 172.1 vs. 166.5
  avg. distance between (yok): 128.7 vs. 151.5
training 3
  avg. time between [s]: 6.3 vs. 5.5
  avg. distance between (exp): 141.0 vs. 103.9
  avg. distance between (yok): 273.8 vs. 223.3

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 9.0 vs. 6.9
  avg. time between [s] (yok): 11.0 vs. 9.1
  avg. distance between (exp): 285.6 vs. 244.3
  avg. distance between (yok): 424.2 vs. 322.6
training 2
  avg. time between [s] (exp): 4.7 vs. 5.1
  avg. time between [s] (yok): 9.5 vs. 11.5
  avg. distance between (exp): 221.7 vs. 197.3
  avg. distance between (yok): 335.2 vs. 384.0
training 3
  avg. time between [s] (exp): 6.9 vs. 6.5
  avg. time between [s] (yok): 6.0 vs. 7.3
  avg. distance between (exp): 153.2 vs. 121.2
  avg. distance between (yok): 260.5 vs. 302.2

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.1, 4.6, stop fraction: 0.47, 0.38
  yok: avg. speed bottom [mm/s]: 3.6, 4.7, stop fraction: 0.41, 0.32
training 2
  exp: avg. speed bottom [mm/s]: 3.0, 4.1, stop fraction: 0.44, 0.35
  yok: avg. speed bottom [mm/s]: 2.8, 4.5, stop fraction: 0.54, 0.35
training 3
  exp: avg. speed bottom [mm/s]: 3.2, 2.7, stop fraction: 0.38, 0.51
  yok: avg. speed bottom [mm/s]: 2.6, 5.3, stop fraction: 0.56, 0.26

rewards per distance traveled [m⁻¹]
training 1
  exp: 24.21, 31.69, 35.23, 36.22, 31.25
  yok: 13.31, 27.90, 21.32, 25.76, 17.19
training 2
  exp: 37.62, 39.17, 40.25, 79.36, 63.02
  yok: 19.13, 24.74, 21.90, 21.88, 33.31
training 3
  exp: 51.87, 70.71, 36.27, 33.32, 53.03
  yok: 31.23, 26.79, 27.67, 26.12, 22.60

=== analyzing c1__2025-07-08__12-52-04.avi, fly 2 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=343,y=87,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=343,y=87,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=343,y=87,r=10)

processing trajectories...
exp fly
  lost: number frames: 3187 (2.95%), sequence length: avg: 3.0, max: 39
    during "on" (3129 frames, 2 per "on" cmd): 367 (11.73%)
    interpolating...
  long (>30) jumps: 4, suspicious: 0 (0.0%)
  total calculated rewards during training: 1444
    for zero-width border: 1716 (+18.8%)
      compared with actual ones: only calc.: 433, only actual: 278
  total control rewards during trainings 1, 2, and 3: 2577
yok fly
  lost: number frames: 3548 (3.28%), sequence length: avg: 1.7, max: 64
    during "on" (3129 frames, 2 per "on" cmd): 124 (3.96%)
    interpolating...
  long (>30) jumps: 13, suspicious: 0 (0.0%)
  total calculated rewards during training: 898
  total control rewards during trainings 1, 2, and 3: 2395

total rewards training: 1563, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 93, 121, 126, 119, 134
  calc. exp: 74, 105, 113, 103, 113
  ctrl. exp: 172, 247, 221, 230, 238
    PI: -0.40, -0.40, -0.32, -0.38, -0.36
  calc. yok: 43, 46, 53, 48, 50
  ctrl. yok: 103, 107, 108, 123, 116
    PI: -0.41, -0.40, -0.34, -0.44, -0.40
training 2
  actual: 126, 95, 75, 57, 72
  calc. exp: 102, 95, 75, 51, 81
  ctrl. exp: 272, 107, 93, 118, 90
    PI: -0.45, -0.06, -0.11, -0.40, -0.05
  calc. yok: 69, 43, 50, 40, 46
  ctrl. yok: 184, 126, 115, 127, 143
    PI: -0.45, -0.49, -0.39, -0.52, -0.51
training 3
  actual: 64, 84, 69, 52, 51
  calc. exp: 61, 80, 71, 49, 52
  ctrl. exp: 101, 61, 72, 60, 59
    PI: -0.25, 0.13, -0.01, -0.10, -0.06
  calc. yok: 56, 58, 35, 53, 60
  ctrl. yok: 157, 145, 125, 154, 157
    PI: -0.47, -0.43, -0.56, -0.49, -0.45

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 216.1, 176.0, 163.4, 176.5, 151.3
  yok: 335.3, 235.0, 218.8, 262.7, 228.3
training 2
  exp: 191.2, 133.8, 166.3, 204.3, 163.2
  yok: 280.7, 332.5, 450.0, 543.4, 512.8
training 3
  exp: 200.5, 109.9, 127.2, 169.0, 179.0
  yok: 543.6, 383.2, 485.4, 629.1, 696.7

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (28), 30, 18, 14, 22, 13
  calc. yok: (12), 5, 8, 5, 7, 2
training 2
  calc. exp: (10), 15, 4, 7, 5, 9
  calc. yok: (4), 9, 4, 7, 4, 7
training 3
  calc. exp: (6), 5, 3, 5, 4, 8
  calc. yok: (20), 8, 10, 6, 7, 9

reward PI by post bucket (3 min)
training 1
  exp: -0.34, -0.53, -0.58, -0.36, -0.41
  yok: -0.60, -0.30, -0.44, -0.36, -0.69
training 2
  exp: -0.24, -0.76, -0.64, -0.71, -0.49
  yok: -0.42, -0.38, -0.44, -0.60, -0.48
training 3
  exp: -0.60, -0.79, -0.63, -0.65, -0.57
  yok: -0.30, -0.39, -0.54, -0.44, -0.38

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 6.6 vs. 4.7
  avg. distance between (exp): 225.0 vs. 176.4
  avg. distance between (yok): 347.6 vs. 233.7
training 2
  avg. time between [s]: 4.8 vs. 5.5
  avg. distance between (exp): 204.4 vs. 137.1
  avg. distance between (yok): 284.8 vs. 291.7
training 3
  avg. time between [s]: 8.4 vs. 8.8
  avg. distance between (exp): 165.6 vs. 136.5
  avg. distance between (yok): 492.5 vs. 487.5

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 8.0 vs. 4.8
  avg. time between [s] (yok): 13.2 vs. 11.3
  avg. distance between (exp): 273.7 vs. 180.3
  avg. distance between (yok): 665.8 vs. 556.9
training 2
  avg. time between [s] (exp): 5.9 vs. 6.3
  avg. time between [s] (yok): 10.3 vs. 13.5
  avg. distance between (exp): 239.3 vs. 133.0
  avg. distance between (yok): 573.4 vs. 771.1
training 3
  avg. time between [s] (exp): 8.6 vs. 8.6
  avg. time between [s] (yok): 10.1 vs. 13.7
  avg. distance between (exp): 168.6 vs. 133.9
  avg. distance between (yok): 581.5 vs. 756.7

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.3, 4.4, stop fraction: 0.44, 0.32
  yok: avg. speed bottom [mm/s]: 4.0, 6.2, stop fraction: 0.34, 0.22
training 2
  exp: avg. speed bottom [mm/s]: 4.6, 3.0, stop fraction: 0.29, 0.44
  yok: avg. speed bottom [mm/s]: 6.6, 7.1, stop fraction: 0.15, 0.17
training 3
  exp: avg. speed bottom [mm/s]: 4.1, 2.1, stop fraction: 0.31, 0.58
  yok: avg. speed bottom [mm/s]: 6.3, 7.0, stop fraction: 0.19, 0.17

rewards per distance traveled [m⁻¹]
training 1
  exp: 29.45, 39.01, 44.72, 40.13, 45.55
  yok: 11.10, 12.60, 15.65, 12.55, 13.36
training 2
  exp: 34.47, 60.67, 48.64, 30.87, 56.72
  yok: 15.88, 11.02, 11.94, 9.39, 10.27
training 3
  exp: 37.87, 69.66, 65.77, 45.16, 45.28
  yok: 12.63, 14.37, 8.50, 13.08, 13.71

=== analyzing c1__2025-07-08__12-52-04.avi, fly 3 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=490,y=87,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=490,y=87,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=490,y=87,r=10)

processing trajectories...
exp fly
  lost: number frames: 3278 (3.03%), sequence length: avg: 2.8, max: 45
    during "on" (3557 frames, 2 per "on" cmd): 242 (6.80%)
    interpolating...
  long (>30) jumps: 8, suspicious: 0 (0.0%)
  total calculated rewards during training: 1666
    for zero-width border: 2065 (+23.9%)
      compared with actual ones: only calc.: 602, only actual: 306
  total control rewards during trainings 1, 2, and 3: 2073
yok fly
  lost: number frames: 12952 (11.98%) *** bad ***

total rewards training: 1791, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 93, 96, 111, 93, 97
  calc. exp: 81, 71, 93, 87, 90
  ctrl. exp: 152, 185, 162, 191, 175
    PI: -0.30, -0.45, -0.27, -0.37, -0.32
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 2
  actual: 124, 106, 110, 105, 81
  calc. exp: 114, 103, 101, 108, 77
  ctrl. exp: 104, 120, 105, 97, 132
    PI: 0.05, -0.08, -0.02, 0.05, -0.26
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 3
  actual: 90, 103, 98, 80, 105
  calc. exp: 92, 97, 111, 79, 98
  ctrl. exp: 71, 50, 47, 56, 64
    PI: 0.13, 0.32, 0.41, 0.17, 0.21
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 216.3, 203.5, 167.2, 231.5, 198.2
  yok: trajectory bad
training 2
  exp: 119.9, 144.2, 125.9, 123.1, 202.9
  yok: trajectory bad
training 3
  exp: 115.4, 96.5, 93.1, 131.8, 105.5
  yok: trajectory bad

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (22), 19, 14, 16, 22, 20
  calc. yok: trajectory bad
training 2
  calc. exp: (29), 19, 13, 9, 15, 15
  calc. yok: trajectory bad
training 3
  calc. exp: (32), 7, 7, 4, 7, 13
  calc. yok: trajectory bad

reward PI by post bucket (3 min)
training 1
  exp: -0.44, -0.47, -0.38, -0.41, -0.33
  yok: trajectory bad
training 2
  exp: -0.48, -0.37, -0.62, -0.49, -0.43
  yok: trajectory bad
training 3
  exp: -0.71, -0.55, -0.78, -0.53, -0.24
  yok: trajectory bad

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 6.4 vs. 6.2
  avg. distance between (exp): 213.6 vs. 205.5
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s]: 4.9 vs. 5.4
  avg. distance between (exp): 123.5 vs. 133.2
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s]: 6.7 vs. 5.6
  avg. distance between (exp): 120.2 vs. 87.2
  avg. distance between (yok): trajectory bad

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 7.4 vs. 8.3
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 252.3 vs. 272.6
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s] (exp): 5.1 vs. 5.7
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 128.5 vs. 137.4
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s] (exp): 6.7 vs. 5.8
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 117.6 vs. 90.2
  avg. distance between (yok): trajectory bad

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.1, 4.1, stop fraction: 0.39, 0.46
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 2
  exp: avg. speed bottom [mm/s]: 5.5, 3.1, stop fraction: 0.23, 0.47
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 3
  exp: avg. speed bottom [mm/s]: 5.5, 2.2, stop fraction: 0.23, 0.59
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad

rewards per distance traveled [m⁻¹]
training 1
  exp: 32.61, 28.73, 40.52, 33.03, 37.44
  yok: trajectory bad
training 2
  exp: 61.83, 55.03, 58.52, 68.20, 37.65
  yok: trajectory bad
training 3
  exp: 72.17, 79.83, 99.54, 61.71, 72.60
  yok: trajectory bad

=== analyzing c1__2025-07-08__12-52-04.avi, fly 4 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=636,y=87,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=636,y=87,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=636,y=87,r=10)

processing trajectories...
exp fly
  lost: number frames: 1816 (1.68%), sequence length: avg: 1.9, max: 20
    during "on" (5219 frames, 2 per "on" cmd): 170 (3.26%)
    interpolating...
  long (>30) jumps: 11, suspicious: 0 (0.0%)
  total calculated rewards during training: 2166
    for zero-width border: 2488 (+14.9%)
      compared with actual ones: only calc.: 504, only actual: 617
  total control rewards during trainings 1, 2, and 3: 2780
yok fly
  lost: number frames: 10433 (9.65%), sequence length: avg: 3.6, max: 61
    during "on" (5219 frames, 2 per "on" cmd): 531 (10.17%)
    interpolating...
  long (>30) jumps: 5, suspicious: 0 (0.0%)
  total calculated rewards during training: 742
  total control rewards during trainings 1, 2, and 3: 2222

total rewards training: 2650, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 142, 159, 187, 169, 189
  calc. exp: 106, 117, 139, 127, 132
  ctrl. exp: 254, 281, 263, 279, 276
    PI: -0.41, -0.41, -0.31, -0.37, -0.35
  calc. yok: 47, 46, 47, 34, 35
  ctrl. yok: 126, 131, 130, 104, 105
    PI: -0.46, -0.48, -0.47, -0.51, -0.50
training 2
  actual: 181, 187, 191, 149, 103
  calc. exp: 144, 165, 164, 135, 91
  ctrl. exp: 215, 70, 38, 61, 98
    PI: -0.20, 0.40, 0.62, 0.38, -0.04
  calc. yok: 55, 31, 38, 35, 33
  ctrl. yok: 117, 125, 136, 108, 106
    PI: -0.36, -0.60, -0.56, -0.51, -0.53
training 3
  actual: 124, 152, 137, 115, 96
  calc. exp: 98, 143, 123, 94, 81
  ctrl. exp: 121, 53, 77, 73, 117
    PI: -0.11, 0.46, 0.23, 0.13, -0.18
  calc. yok: 43, 60, 41, 28, 38
  ctrl. yok: 138, 126, 145, 127, 116
    PI: -0.52, -0.35, -0.56, -0.64, -0.51

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 218.0, 186.2, 154.6, 161.4, 143.5
  yok: 180.6, 128.1, 118.2, 137.3, 110.4
training 2
  exp: 129.8, 79.3, 59.2, 88.5, 125.2
  yok: 138.7, 132.7, 124.2, 163.9, 263.7
training 3
  exp: 127.9, 79.0, 90.6, 108.1, 142.7
  yok: 221.6, 168.9, 186.2, 221.5, 244.4

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (46), 25, 12, 8, 8, 11
  calc. yok: (19), 18, 9, 11, 10, 8
training 2
  calc. exp: (36), 18, 13, 17, 16, 9
  calc. yok: (14), 13, 5, 6, 6, 7
training 3
  calc. exp: (14), 9, 10, 7, 5, 10
  calc. yok: (7), 11, 7, 5, 10, 8

reward PI by post bucket (3 min)
training 1
  exp: -0.54, -0.69, -0.71, -0.68, -0.51
  yok: -0.39, -0.56, -0.35, -0.33, -0.45
training 2
  exp: -0.33, -0.55, -0.35, -0.43, -0.59
  yok: -0.41, -0.58, -0.48, -0.50, -0.36
training 3
  exp: -0.60, -0.44, -0.64, -0.60, -0.31
  yok: -0.49, -0.46, -0.47, -0.31, -0.30

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 4.3 vs. 3.9
  avg. distance between (exp): 230.2 vs. 192.5
  avg. distance between (yok): 177.8 vs. 168.2
training 2
  avg. time between [s]: 3.4 vs. 3.2
  avg. distance between (exp): 151.5 vs. 100.2
  avg. distance between (yok): 158.5 vs. 126.1
training 3
  avg. time between [s]: 4.7 vs. 3.9
  avg. distance between (exp): 137.9 vs. 78.5
  avg. distance between (yok): 219.1 vs. 176.7

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 5.7 vs. 5.1
  avg. time between [s] (yok): 12.4 vs. 15.3
  avg. distance between (exp): 295.6 vs. 254.7
  avg. distance between (yok): 471.5 vs. 562.1
training 2
  avg. time between [s] (exp): 4.2 vs. 3.8
  avg. time between [s] (yok): 14.2 vs. 16.3
  avg. distance between (exp): 178.4 vs. 114.1
  avg. distance between (yok): 599.3 vs. 690.7
training 3
  avg. time between [s] (exp): 6.1 vs. 3.8
  avg. time between [s] (yok): 11.3 vs. 17.3
  avg. distance between (exp): 163.9 vs. 75.3
  avg. distance between (yok): 512.6 vs. 724.2

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 5.1, 5.9, stop fraction: 0.30, 0.32
  yok: avg. speed bottom [mm/s]: 4.6, 4.9, stop fraction: 0.30, 0.38
training 2
  exp: avg. speed bottom [mm/s]: 5.7, 3.1, stop fraction: 0.27, 0.44
  yok: avg. speed bottom [mm/s]: 5.2, 5.6, stop fraction: 0.26, 0.28
training 3
  exp: avg. speed bottom [mm/s]: 4.9, 2.8, stop fraction: 0.25, 0.44
  yok: avg. speed bottom [mm/s]: 5.5, 5.7, stop fraction: 0.28, 0.24

rewards per distance traveled [m⁻¹]
training 1
  exp: 27.86, 32.21, 39.24, 38.03, 39.62
  yok: 14.90, 18.45, 17.39, 12.00, 13.60
training 2
  exp: 49.73, 90.54, 117.43, 83.52, 55.81
  yok: 17.67, 10.17, 12.91, 11.71, 9.66
training 3
  exp: 49.77, 96.34, 80.72, 60.51, 47.24
  yok: 12.45, 19.04, 13.01, 8.89, 12.56

=== analyzing c1__2025-07-08__12-52-04.avi, fly 5 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=50,y=266,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=50,y=266,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=50,y=266,r=10)

processing trajectories...
exp fly
  lost: number frames: 6426 (5.94%), sequence length: avg: 3.3, max: 362
    during "on" (3046 frames, 2 per "on" cmd): 324 (10.64%)
    interpolating...
  long (>30) jumps: 2, suspicious: 0 (0.0%)
  total calculated rewards during training: 1277
    for zero-width border: 1443 (+13.0%)
      compared with actual ones: only calc.: 269, only actual: 348
  total control rewards during trainings 1, 2, and 3: 2340
yok fly
  lost: number frames: 22151 (20.48%) *** bad ***

total rewards training: 1524, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 61, 127, 149, 139, 161
  calc. exp: 48, 95, 110, 103, 121
  ctrl. exp: 157, 203, 219, 194, 195
    PI: -0.53, -0.36, -0.33, -0.31, -0.23
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 2
  actual: 90, 47, 45, 51, 39
  calc. exp: 67, 41, 44, 50, 32
  ctrl. exp: 149, 130, 124, 112, 99
    PI: -0.38, -0.52, -0.48, -0.38, -0.51
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 3
  actual: 81, 53, 77, 70, 72
  calc. exp: 72, 55, 67, 66, 67
  ctrl. exp: 92, 81, 59, 64, 68
    PI: -0.12, -0.19, 0.06, 0.02, -0.01
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 422.7, 164.9, 144.9, 137.7, 125.0
  yok: trajectory bad
training 2
  exp: 170.5, 269.0, 308.4, 273.2, 299.1
  yok: trajectory bad
training 3
  exp: 156.2, 202.6, 133.7, 131.2, 154.0
  yok: trajectory bad

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (30), 21, 17, 15, 6, 12
  calc. yok: trajectory bad
training 2
  calc. exp: (18), 4, 8, 7, 11, 9
  calc. yok: trajectory bad
training 3
  calc. exp: (17), 8, 6, 7, 6, 7
  calc. yok: trajectory bad

reward PI by post bucket (3 min)
training 1
  exp: -0.35, -0.50, -0.49, -0.70, -0.48
  yok: trajectory bad
training 2
  exp: -0.60, -0.59, -0.58, -0.39, -0.54
  yok: trajectory bad
training 3
  exp: -0.52, -0.71, -0.64, -0.56, -0.53
  yok: trajectory bad

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 8.0 vs. 4.5
  avg. distance between (exp): 347.0 vs. 171.8
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s]: 7.2 vs. 13.5
  avg. distance between (exp): 209.6 vs. 341.8
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s]: 8.1 vs. 9.3
  avg. distance between (exp): 159.7 vs. 175.6
  avg. distance between (yok): trajectory bad

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 9.5 vs. 5.4
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 404.2 vs. 193.5
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s] (exp): 10.7 vs. 12.7
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 290.6 vs. 311.8
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s] (exp): 9.1 vs. 9.2
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 183.2 vs. 163.0
  avg. distance between (yok): trajectory bad

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.3, 4.5, stop fraction: 0.36, 0.43
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 2
  exp: avg. speed bottom [mm/s]: 5.3, 3.0, stop fraction: 0.30, 0.46
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 3
  exp: avg. speed bottom [mm/s]: 4.1, 2.3, stop fraction: 0.38, 0.54
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad

rewards per distance traveled [m⁻¹]
training 1
  exp: 14.61, 33.99, 41.59, 43.64, 49.21
  yok: trajectory bad
training 2
  exp: 31.49, 22.78, 23.85, 29.17, 21.71
  yok: trajectory bad
training 3
  exp: 46.37, 40.65, 51.04, 57.28, 49.46
  yok: trajectory bad

=== analyzing c1__2025-07-08__12-52-04.avi, fly 6 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=196,y=266,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=196,y=266,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=196,y=266,r=10)

processing trajectories...
exp fly
  lost: number frames: 10101 (9.34%), sequence length: avg: 2.8, max: 86
    during "on" (6268 frames, 2 per "on" cmd): 466 (7.43%)
    interpolating...
  long (>30) jumps: 1, suspicious: 0 (0.0%)
  total calculated rewards during training: 2806
    for zero-width border: 2993 (+6.7%)
      compared with actual ones: only calc.: 274, only actual: 411
  total control rewards during trainings 1, 2, and 3: 3483
yok fly
  lost: number frames: 10429 (9.64%), sequence length: avg: 8.8, max: 638
    during "on" (6268 frames, 2 per "on" cmd): 474 (7.56%)
    interpolating...
  long (>30) jumps: 9, suspicious: 0 (0.0%)
  total calculated rewards during training: 106
  total control rewards during trainings 1, 2, and 3: 481

total rewards training: 3132, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 169, 167, 174, 167, 187
  calc. exp: 145, 145, 152, 147, 159
  ctrl. exp: 283, 253, 263, 253, 236
    PI: -0.32, -0.27, -0.27, -0.27, -0.19
  calc. yok: 12, 3, 21, 15, 2
  ctrl. yok: 51, 26, 51, 35, 28
    PI: -0.62, -0.79, -0.42, -0.40, -0.87
training 2
  actual: 177, 162, 171, 178, 177
  calc. exp: 154, 136, 151, 154, 158
  ctrl. exp: 256, 244, 234, 211, 203
    PI: -0.25, -0.28, -0.22, -0.16, -0.12
  calc. yok: 4, 8, 10, 0, 3
  ctrl. yok: 31, 24, 34, 0, 11
    PI: -0.77, -0.50, -0.55, nan, -0.57
training 3
  actual: 178, 184, 179, 181, 165
  calc. exp: 161, 174, 166, 175, 146
  ctrl. exp: 135, 80, 93, 75, 142
    PI: 0.09, 0.37, 0.28, 0.40, 0.01
  calc. yok: 5, 2, 0, 0, 0
  ctrl. yok: 34, 40, 5, 0, 0
    PI: -0.74, -0.90, nan, nan, nan

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 163.7, 144.9, 141.4, 144.9, 127.1
  yok: 51.4, 55.4, 67.3, 60.1, 52.0
training 2
  exp: 148.6, 152.4, 135.8, 125.9, 128.4
  yok: 64.8, 67.6, 61.3, 39.9, 53.4
training 3
  exp: 106.1, 81.0, 88.5, 82.6, 111.6
  yok: 61.2, 46.4, 39.4, 34.2, 40.1

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (45), 36, 32, 32, 14, 17
  calc. yok: (5), 9, 1, 4, 3, 2
training 2
  calc. exp: (45), 33, 24, 21, 21, 24
  calc. yok: (3), 0, 2, 3, 4, 3
training 3
  calc. exp: (57), 23, 29, 21, 17, 13
  calc. yok: (0), 0, 3, 0, 1, 1

reward PI by post bucket (3 min)
training 1
  exp: -0.29, -0.28, -0.31, -0.52, -0.47
  yok: -0.14, nan, -0.58, -0.40, -0.60
training 2
  exp: -0.30, -0.44, -0.38, -0.38, -0.39
  yok: nan, nan, -0.45, -0.33, nan
training 3
  exp: -0.35, -0.33, -0.42, -0.45, -0.56
  yok: nan, -0.62, nan, nan, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 3.5 vs. 3.7
  avg. distance between (exp): 171.8 vs. 157.3
  avg. distance between (yok): 54.7 vs. 46.1
training 2
  avg. time between [s]: 3.5 vs. 3.3
  avg. distance between (exp): 154.2 vs. 142.4
  avg. distance between (yok): 69.0 vs. 57.7
training 3
  avg. time between [s]: 3.3 vs. 3.3
  avg. distance between (exp): 115.8 vs. 97.5
  avg. distance between (yok): 65.6 vs. 53.2

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 4.0 vs. 4.4
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 191.1 vs. 187.1
  avg. distance between (yok): nan vs. nan
training 2
  avg. time between [s] (exp): 4.0 vs. 4.2
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 176.1 vs. 178.6
  avg. distance between (yok): nan vs. nan
training 3
  avg. time between [s] (exp): 3.8 vs. 3.6
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 130.0 vs. 104.0
  avg. distance between (yok): nan vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.4, 5.3, stop fraction: 0.44, 0.33
  yok: avg. speed bottom [mm/s]: 2.1, 2.2, stop fraction: 0.77, 0.63
training 2
  exp: avg. speed bottom [mm/s]: 5.0, 4.9, stop fraction: 0.25, 0.33
  yok: avg. speed bottom [mm/s]: 2.0, 2.1, stop fraction: 0.65, 0.65
training 3
  exp: avg. speed bottom [mm/s]: 5.3, 3.5, stop fraction: 0.23, 0.41
  yok: avg. speed bottom [mm/s]: 2.4, 1.8, stop fraction: 0.67, 0.72

rewards per distance traveled [m⁻¹]
training 1
  exp: 42.40, 47.56, 50.55, 48.03, 54.57
  yok: 11.23, 2.62, 14.69, 11.74, 1.68
training 2
  exp: 47.67, 44.70, 52.93, 55.50, 56.62
  yok: 2.84, 5.92, 7.78, 0.00, 2.58
training 3
  exp: 69.17, 94.64, 85.11, 95.50, 64.35
  yok: 3.72, 1.90, 0.00, 0.00, 0.00

=== analyzing c1__2025-07-08__12-52-04.avi, fly 7 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=343,y=266,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=343,y=266,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=343,y=266,r=10)

processing trajectories...
exp fly
  lost: number frames: 1072 (0.99%), sequence length: avg: 1.5, max: 12
    during "on" (5232 frames, 2 per "on" cmd): 214 (4.09%)
    interpolating...
  long (>30) jumps: 3, suspicious: 0 (0.0%)
  total calculated rewards during training: 2520
    for zero-width border: 2813 (+11.6%)
      compared with actual ones: only calc.: 431, only actual: 232
  total control rewards during trainings 1, 2, and 3: 2344
yok fly
  lost: number frames: 6441 (5.96%), sequence length: avg: 3.5, max: 77
    during "on" (5232 frames, 2 per "on" cmd): 304 (5.81%)
    interpolating...
  long (>30) jumps: 11, suspicious: 0 (0.0%)
  total calculated rewards during training: 782
  total control rewards during trainings 1, 2, and 3: 2216

total rewards training: 2614, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 152, 187, 200, 202, 201
  calc. exp: 140, 171, 185, 185, 177
  ctrl. exp: 242, 280, 237, 257, 246
    PI: -0.27, -0.24, -0.12, -0.16, -0.16
  calc. yok: 47, 42, 53, 54, 59
  ctrl. yok: 142, 110, 127, 145, 192
    PI: -0.50, -0.45, -0.41, -0.46, -0.53
training 2
  actual: 162, 115, 115, 125, 122
  calc. exp: 145, 115, 113, 128, 125
  ctrl. exp: 247, 104, 74, 45, 43
    PI: -0.26, 0.05, 0.21, 0.48, 0.49
  calc. yok: 63, 56, 54, 29, 26
  ctrl. yok: 157, 144, 132, 104, 92
    PI: -0.43, -0.44, -0.42, -0.56, -0.56
training 3
  actual: 135, 130, 105, 112, 107
  calc. exp: 140, 133, 106, 115, 112
  ctrl. exp: 38, 36, 40, 65, 28
    PI: 0.57, 0.57, 0.45, 0.28, 0.60
  calc. yok: 43, 48, 41, 32, 31
  ctrl. yok: 123, 127, 108, 94, 103
    PI: -0.48, -0.45, -0.45, -0.49, -0.54

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 171.7, 128.9, 112.7, 115.2, 117.0
  yok: 168.6, 123.7, 110.7, 114.6, 125.9
training 2
  exp: 139.8, 122.6, 103.9, 75.3, 79.0
  yok: 150.5, 207.1, 197.8, 156.1, 160.3
training 3
  exp: 81.0, 78.5, 89.8, 98.9, 90.8
  yok: 148.3, 147.4, 182.6, 152.2, 181.5

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (64), 39, 32, 20, 21, 16
  calc. yok: (14), 13, 14, 8, 8, 4
training 2
  calc. exp: (38), 21, 11, 18, 13, 13
  calc. yok: (16), 14, 7, 14, 7, 10
training 3
  calc. exp: (36), 18, 11, 10, 7, 10
  calc. yok: (4), 7, 2, 4, 6, 6

reward PI by post bucket (3 min)
training 1
  exp: -0.17, -0.30, -0.38, -0.32, -0.48
  yok: -0.56, -0.51, -0.54, -0.48, -0.64
training 2
  exp: 0.00, -0.31, -0.39, -0.50, -0.53
  yok: -0.18, -0.56, -0.22, -0.50, -0.38
training 3
  exp: -0.38, -0.41, -0.52, -0.62, -0.56
  yok: -0.48, -0.73, -0.74, -0.45, -0.48

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 4.2 vs. 3.4
  avg. distance between (exp): 187.4 vs. 139.1
  avg. distance between (yok): 179.1 vs. 139.8
training 2
  avg. time between [s]: 3.4 vs. 4.4
  avg. distance between (exp): 128.8 vs. 158.9
  avg. distance between (yok): 145.1 vs. 175.5
training 3
  avg. time between [s]: 4.3 vs. 4.5
  avg. distance between (exp): 83.4 vs. 75.2
  avg. distance between (yok): 149.6 vs. 144.8

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 4.6 vs. 3.6
  avg. time between [s] (yok): 13.1 vs. 11.2
  avg. distance between (exp): 202.5 vs. 147.2
  avg. distance between (yok): 533.0 vs. 422.5
training 2
  avg. time between [s] (exp): 3.7 vs. 4.9
  avg. time between [s] (yok): 10.1 vs. 13.6
  avg. distance between (exp): 140.9 vs. 165.8
  avg. distance between (yok): 410.1 vs. 487.1
training 3
  avg. time between [s] (exp): 3.9 vs. 4.8
  avg. time between [s] (yok): 12.8 vs. 17.9
  avg. distance between (exp): 73.8 vs. 80.9
  avg. distance between (yok): 422.1 vs. 547.3

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.2, 4.9, stop fraction: 0.28, 0.31
  yok: avg. speed bottom [mm/s]: 3.7, 5.0, stop fraction: 0.47, 0.34
training 2
  exp: avg. speed bottom [mm/s]: 5.2, 2.7, stop fraction: 0.19, 0.49
  yok: avg. speed bottom [mm/s]: 4.1, 4.8, stop fraction: 0.35, 0.32
training 3
  exp: avg. speed bottom [mm/s]: 3.1, 2.1, stop fraction: 0.35, 0.54
  yok: avg. speed bottom [mm/s]: 4.6, 3.9, stop fraction: 0.31, 0.36

rewards per distance traveled [m⁻¹]
training 1
  exp: 43.59, 57.91, 67.06, 64.31, 61.40
  yok: 14.91, 14.79, 19.56, 18.98, 19.02
training 2
  exp: 51.21, 66.44, 77.28, 108.46, 104.57
  yok: 20.70, 19.21, 19.45, 11.88, 10.84
training 3
  exp: 103.99, 106.09, 91.51, 85.15, 94.18
  yok: 17.45, 20.23, 17.41, 15.41, 13.08

=== analyzing c1__2025-07-08__12-52-04.avi, fly 8 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=490,y=266,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=490,y=266,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=490,y=266,r=10)

processing trajectories...
exp fly
  lost: number frames: 1381 (1.28%), sequence length: avg: 1.3, max: 14
    during "on" (5287 frames, 2 per "on" cmd): 9 (0.17%)
    interpolating...
  long (>30) jumps: 6, suspicious: 0 (0.0%)
  total calculated rewards during training: 2442
    for zero-width border: 2661 (+9.0%)
      compared with actual ones: only calc.: 307, only actual: 288
  total control rewards during trainings 1, 2, and 3: 3811
yok fly
  lost: number frames: 7699 (7.13%), sequence length: avg: 23.1, max: 3350
    during "on" (5287 frames, 2 per "on" cmd): 467 (8.83%)
    interpolating...
  long (>30) jumps: 0, suspicious: 0
  total calculated rewards during training: 49
  total control rewards during trainings 1, 2, and 3: 127

total rewards training: 2643, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 115, 134, 143, 149, 152
  calc. exp: 107, 116, 128, 138, 135
  ctrl. exp: 255, 305, 305, 308, 300
    PI: -0.41, -0.45, -0.41, -0.38, -0.38
  calc. yok: 0, 6, 8, 0, 6
  ctrl. yok: 0, 10, 10, 1, 7
    PI: nan, -0.25, -0.11, nan, -0.08
training 2
  actual: 177, 155, 148, 158, 156
  calc. exp: 151, 145, 125, 139, 142
  ctrl. exp: 321, 309, 280, 267, 269
    PI: -0.36, -0.36, -0.38, -0.32, -0.31
  calc. yok: 3, 1, 0, 0, 2
  ctrl. yok: 7, 6, 4, 2, 9
    PI: -0.40, nan, nan, nan, -0.64
training 3
  actual: 160, 151, 148, 132, 136
  calc. exp: 149, 143, 150, 134, 129
  ctrl. exp: 195, 50, 32, 35, 30
    PI: -0.13, 0.48, 0.65, 0.59, 0.62
  calc. yok: 9, 5, 0, 0, 0
  ctrl. yok: 9, 28, 1, 1, 1
    PI: 0.00, -0.70, nan, nan, nan

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 294.7, 233.1, 217.3, 200.9, 192.1
  yok: 18.3, 21.7, 20.6, 18.8, 17.2
training 2
  exp: 173.4, 183.6, 179.8, 164.4, 166.9
  yok: 17.3, 16.5, 16.0, 15.2, 16.5
training 3
  exp: 144.7, 88.7, 75.0, 85.0, 78.8
  yok: 16.8, 23.6, 14.0, 21.6, 23.5

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (43), 34, 29, 32, 26, 36
  calc. yok: (3), 0, 1, 0, 0, 0
training 2
  calc. exp: (46), 30, 16, 17, 18, 19
  calc. yok: (0), 0, 0, 0, 0, 0
training 3
  calc. exp: (36), 20, 11, 7, 10, 13
  calc. yok: (2), 1, 0, 1, 2, 0

reward PI by post bucket (3 min)
training 1
  exp: -0.33, -0.39, -0.30, -0.32, -0.25
  yok: nan, nan, nan, nan, nan
training 2
  exp: -0.47, -0.56, -0.63, -0.57, -0.46
  yok: nan, nan, nan, nan, nan
training 3
  exp: -0.44, -0.63, -0.73, -0.53, -0.56
  yok: nan, nan, nan, nan, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 5.3 vs. 4.5
  avg. distance between (exp): 301.1 vs. 236.8
  avg. distance between (yok): 18.2 vs. 22.3
training 2
  avg. time between [s]: 3.0 vs. 3.7
  avg. distance between (exp): 158.9 vs. 185.8
  avg. distance between (yok): 16.3 vs. 16.3
training 3
  avg. time between [s]: 3.7 vs. 3.6
  avg. distance between (exp): 163.6 vs. 98.8
  avg. distance between (yok): 11.7 vs. 21.8

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 5.6 vs. 5.2
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 317.4 vs. 276.8
  avg. distance between (yok): nan vs. nan
training 2
  avg. time between [s] (exp): 3.8 vs. 4.4
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 199.2 vs. 215.1
  avg. distance between (yok): nan vs. nan
training 3
  avg. time between [s] (exp): 4.0 vs. 4.0
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 178.4 vs. 101.6
  avg. distance between (yok): nan vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.1, 6.4, stop fraction: 0.34, 0.30
  yok: avg. speed bottom [mm/s]: 0.4, 0.6, stop fraction: 1.00, 0.98
training 2
  exp: avg. speed bottom [mm/s]: 6.8, 5.6, stop fraction: 0.18, 0.33
  yok: avg. speed bottom [mm/s]: 0.6, 0.5, stop fraction: 0.99, 0.98
training 3
  exp: avg. speed bottom [mm/s]: 7.1, 2.8, stop fraction: 0.16, 0.49
  yok: avg. speed bottom [mm/s]: 0.6, 0.8, stop fraction: 1.00, 0.96

rewards per distance traveled [m⁻¹]
training 1
  exp: 25.76, 29.65, 33.69, 37.65, 37.56
  yok: 0.00, 16.49, 21.99, 0.00, 18.66
training 2
  exp: 40.07, 41.12, 37.94, 43.63, 43.91
  yok: 7.99, 3.18, 0.00, 0.00, 6.33
training 3
  exp: 52.27, 87.18, 109.83, 97.54, 97.72
  yok: 27.16, 11.43, 0.00, 0.00, 0.00

=== analyzing c1__2025-07-08__12-52-04.avi, fly 9 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=636,y=266,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=636,y=266,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=636,y=266,r=10)

processing trajectories...
exp fly
  lost: number frames: 738 (0.68%), sequence length: avg: 1.5, max: 7
    during "on" (3726 frames, 2 per "on" cmd): 47 (1.26%)
    interpolating...
  long (>30) jumps: 13, suspicious: 0 (0.0%)
  total calculated rewards during training: 1648
    for zero-width border: 1921 (+16.6%)
      compared with actual ones: only calc.: 399, only actual: 331
  total control rewards during trainings 1, 2, and 3: 2330
yok fly
  lost: number frames: 15632 (14.46%) *** bad ***

total rewards training: 1911, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 106, 158, 152, 108, 73
  calc. exp: 87, 142, 133, 98, 67
  ctrl. exp: 197, 235, 209, 194, 144
    PI: -0.39, -0.25, -0.22, -0.33, -0.36
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 2
  actual: 121, 95, 111, 98, 134
  calc. exp: 116, 80, 107, 82, 102
  ctrl. exp: 143, 116, 89, 79, 97
    PI: -0.10, -0.18, 0.09, 0.02, 0.03
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 3
  actual: 75, 105, 108, 82, 131
  calc. exp: 65, 94, 90, 67, 101
  ctrl. exp: 121, 108, 97, 99, 106
    PI: -0.30, -0.07, -0.04, -0.19, -0.02
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 209.9, 139.4, 143.0, 175.0, 200.3
  yok: trajectory bad
training 2
  exp: 141.8, 151.4, 112.3, 117.7, 90.5
  yok: trajectory bad
training 3
  exp: 204.5, 135.0, 128.7, 160.1, 104.7
  yok: trajectory bad

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (15), 11, 17, 12, 2, 3
  calc. yok: trajectory bad
training 2
  calc. exp: (33), 15, 11, 5, 13, 5
  calc. yok: trajectory bad
training 3
  calc. exp: (12), 5, 7, 8, 6, 20
  calc. yok: trajectory bad

reward PI by post bucket (3 min)
training 1
  exp: -0.58, -0.41, -0.41, -0.82, -0.70
  yok: trajectory bad
training 2
  exp: -0.32, -0.45, -0.70, -0.28, -0.41
  yok: trajectory bad
training 3
  exp: nan, 0.08, 0.14, -0.14, 0.21
  yok: trajectory bad

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 5.7 vs. 4.0
  avg. distance between (exp): 209.6 vs. 149.3
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s]: 5.0 vs. 5.7
  avg. distance between (exp): 148.9 vs. 139.1
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s]: 6.9 vs. 5.8
  avg. distance between (exp): 173.8 vs. 135.5
  avg. distance between (yok): trajectory bad

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 6.5 vs. 4.4
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 242.7 vs. 159.8
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s] (exp): 5.1 vs. 7.0
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 151.7 vs. 166.0
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s] (exp): 7.8 vs. 7.3
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 197.5 vs. 173.3
  avg. distance between (yok): trajectory bad

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.3, 4.1, stop fraction: 0.42, 0.36
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 2
  exp: avg. speed bottom [mm/s]: 3.5, 2.9, stop fraction: 0.38, 0.46
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 3
  exp: avg. speed bottom [mm/s]: 3.2, 2.8, stop fraction: 0.45, 0.49
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad

rewards per distance traveled [m⁻¹]
training 1
  exp: 31.67, 51.76, 49.70, 42.37, 36.04
  yok: trajectory bad
training 2
  exp: 55.12, 45.16, 70.05, 57.64, 63.67
  yok: trajectory bad
training 3
  exp: 34.93, 53.72, 51.59, 41.43, 60.03
  yok: trajectory bad

=== analyzing c1__2025-07-08__12-52-04.avi, fly 10 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 11 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 12 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 13 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 14 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 15 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 16 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 17 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 18 ===

yoked control

=== analyzing c1__2025-07-08__12-52-04.avi, fly 19 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 0 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=52,y=90,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=52,y=90,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=52,y=90,r=10)

processing trajectories...
exp fly
  lost: number frames: 9539 (8.82%), sequence length: avg: 4.6, max: 47
    during "on" (1500 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 23, suspicious: 0 (0.0%)
  total calculated rewards during training: 650
    for zero-width border: 728 (+12.0%)
      compared with actual ones: only calc.: 105, only actual: 126
  total control rewards during trainings 1, 2, and 3: 1496
yok fly
  lost: number frames: 384 (0.36%), sequence length: avg: 1.3, max: 12
    during "on" (1500 frames, 2 per "on" cmd): 8 (0.53%)
    interpolating...
  long (>30) jumps: 24, suspicious: 0 (0.0%)
  total calculated rewards during training: 724
  total control rewards during trainings 1, 2, and 3: 1969

total rewards training: 751, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 67, 47, 32, 72, 31
  calc. exp: 61, 44, 29, 67, 30
  ctrl. exp: 83, 83, 62, 106, 81
    PI: -0.15, -0.31, -0.36, -0.23, -0.46
  calc. yok: 31, 42, 50, 55, 57
  ctrl. yok: 108, 112, 148, 127, 130
    PI: -0.55, -0.45, -0.49, -0.40, -0.39
training 2
  actual: 16, 70, 65, 49, 32
  calc. exp: 14, 60, 48, 37, 28
  ctrl. exp: 51, 98, 102, 96, 68
    PI: -0.57, -0.24, -0.36, -0.44, -0.42
  calc. yok: 51, 25, 41, 63, 43
  ctrl. yok: 120, 125, 115, 126, 110
    PI: -0.40, -0.67, -0.47, -0.33, -0.44
training 3
  actual: 44, 28, 41, 34, 27
  calc. exp: 38, 25, 26, 33, 23
  ctrl. exp: 97, 79, 83, 87, 71
    PI: -0.44, -0.52, -0.52, -0.45, -0.51
  calc. yok: 21, 45, 17, 30, 28
  ctrl. yok: 85, 71, 65, 101, 84
    PI: -0.60, -0.22, -0.59, -0.54, -0.50

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 278.1, 337.3, 526.9, 279.1, 597.1
  yok: 269.9, 346.9, 678.1, 257.3, 604.0
training 2
  exp: 926.9, 292.3, 322.9, 378.0, 611.0
  yok: 943.0, 248.0, 307.6, 343.9, 583.9
training 3
  exp: 443.9, 499.7, 427.5, 498.9, 587.1
  yok: 333.2, 318.2, 333.3, 450.6, 576.2

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (12), 4, 3, 0, 1, 0
  calc. yok: (23), 6, 20, 11, 15, 13
training 2
  calc. exp: (14), 0, 7, 5, 1, 2
  calc. yok: (10), 13, 2, 14, 8, 17
training 3
  calc. exp: (8), 10, 4, 2, 6, 0
  calc. yok: (11), 3, 15, 11, 9, 6

reward PI by post bucket (3 min)
training 1
  exp: -0.38, -0.67, nan, nan, nan
  yok: -0.82, -0.33, -0.35, -0.53, -0.47
training 2
  exp: -1.00, -0.53, -0.55, -0.87, -0.67
  yok: -0.52, -0.88, -0.26, -0.58, -0.40
training 3
  exp: -0.17, -0.33, -0.75, -0.45, nan
  yok: -0.76, -0.27, -0.42, -0.14, -0.50

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 8.7 vs. 14.1
  avg. distance between (exp): 269.7 vs. 421.1
  avg. distance between (yok): 259.0 vs. 486.1
training 2
  avg. time between [s]: 13.2 vs. 10.2
  avg. distance between (exp): 452.1 vs. 369.8
  avg. distance between (yok): 429.3 vs. 351.2
training 3
  avg. time between [s]: 15.8 vs. 19.9
  avg. distance between (exp): 523.3 vs. 577.4
  avg. distance between (yok): 405.9 vs. 514.5

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 9.5 vs. 14.2
  avg. time between [s] (yok): 13.9 vs. 11.1
  avg. distance between (exp): 295.8 vs. 436.0
  avg. distance between (yok): 434.1 vs. 386.4
training 2
  avg. time between [s] (exp): 15.8 vs. 18.0
  avg. time between [s] (yok): 13.5 vs. 12.1
  avg. distance between (exp): 538.0 vs. 614.5
  avg. distance between (yok): 442.3 vs. 407.8
training 3
  avg. time between [s] (exp): 20.1 vs. nan
  avg. time between [s] (yok): 19.4 vs. nan
  avg. distance between (exp): 658.6 vs. nan
  avg. distance between (yok): 503.3 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 2.2, 4.2, stop fraction: 0.63, 0.39
  yok: avg. speed bottom [mm/s]: 4.8, 4.2, stop fraction: 0.39, 0.43
training 2
  exp: avg. speed bottom [mm/s]: 3.7, 4.5, stop fraction: 0.42, 0.36
  yok: avg. speed bottom [mm/s]: 4.5, 4.1, stop fraction: 0.43, 0.45
training 3
  exp: avg. speed bottom [mm/s]: 3.8, 4.1, stop fraction: 0.40, 0.42
  yok: avg. speed bottom [mm/s]: 4.2, 3.2, stop fraction: 0.45, 0.54

rewards per distance traveled [m⁻¹]
training 1
  exp: 26.58, 21.19, 13.71, 25.78, 12.34
  yok: 13.92, 18.71, 18.58, 22.22, 21.23
training 2
  exp: 5.76, 23.41, 18.20, 13.94, 11.83
  yok: 19.77, 11.55, 16.18, 25.01, 18.78
training 3
  exp: 14.84, 10.68, 10.72, 15.11, 11.74
  yok: 10.48, 25.39, 9.25, 14.90, 14.64

=== analyzing c1__2025-07-09__12-47-17.avi, fly 1 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=198,y=90,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=198,y=90,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=198,y=90,r=10)

processing trajectories...
exp fly
  lost: number frames: 2473 (2.29%), sequence length: avg: 2.4, max: 13
    during "on" (3478 frames, 2 per "on" cmd): 1 (0.03%)
    interpolating...
  long (>30) jumps: 120, suspicious: 0 (0.0%)
  total calculated rewards during training: 1430
    for zero-width border: 1498 (+4.8%)
      compared with actual ones: only calc.: 115, only actual: 353
  total control rewards during trainings 1, 2, and 3: 3153
yok fly
  lost: number frames: 1129 (1.04%), sequence length: avg: 1.6, max: 19
    during "on" (3478 frames, 2 per "on" cmd): 86 (2.47%)
    interpolating...
  long (>30) jumps: 7, suspicious: 0 (0.0%)
  total calculated rewards during training: 517
  total control rewards during trainings 1, 2, and 3: 1428

total rewards training: 1742, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 51, 66, 68, 99, 106
  calc. exp: 39, 61, 60, 82, 84
  ctrl. exp: 115, 124, 148, 183, 162
    PI: -0.49, -0.34, -0.42, -0.38, -0.32
  calc. yok: 28, 26, 33, 26, 38
  ctrl. yok: 102, 72, 88, 73, 87
    PI: -0.57, -0.47, -0.45, -0.47, -0.39
training 2
  actual: 101, 90, 96, 105, 116
  calc. exp: 67, 80, 78, 84, 94
  ctrl. exp: 186, 169, 189, 192, 197
    PI: -0.47, -0.36, -0.42, -0.39, -0.35
  calc. yok: 23, 33, 21, 27, 32
  ctrl. yok: 80, 87, 81, 82, 78
    PI: -0.55, -0.45, -0.59, -0.50, -0.42
training 3
  actual: 133, 120, 96, 114, 84
  calc. exp: 110, 95, 79, 104, 75
  ctrl. exp: 207, 212, 175, 199, 161
    PI: -0.31, -0.38, -0.38, -0.31, -0.36
  calc. yok: 28, 34, 32, 22, 36
  ctrl. yok: 69, 80, 78, 55, 95
    PI: -0.42, -0.40, -0.42, -0.43, -0.45

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 525.2, 391.8, 396.6, 311.2, 294.7
  yok: 451.8, 266.8, 240.3, 160.6, 176.3
training 2
  exp: 326.1, 385.6, 382.7, 329.5, 318.3
  yok: 174.5, 194.5, 189.2, 178.2, 153.2
training 3
  exp: 268.9, 283.2, 355.2, 292.9, 392.6
  yok: 117.7, 148.4, 197.8, 141.4, 258.3

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (26), 3, 3, 4, 1, 0
  calc. yok: (6), 5, 2, 5, 4, 6
training 2
  calc. exp: (30), 3, 4, 3, 1, 1
  calc. yok: (10), 8, 4, 4, 4, 6
training 3
  calc. exp: (18), 3, 3, 4, 1, 3
  calc. yok: (11), 4, 1, 3, 6, 3

reward PI by post bucket (3 min)
training 1
  exp: -0.65, -0.62, -0.53, nan, nan
  yok: -0.41, -0.69, -0.38, -0.47, -0.20
training 2
  exp: -0.54, -0.62, -0.57, -0.82, nan
  yok: -0.33, -0.62, -0.53, -0.20, -0.48
training 3
  exp: -0.74, -0.50, -0.47, -0.85, -0.54
  yok: -0.56, -0.83, -0.40, -0.52, -0.54

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 9.5 vs. 9.3
  avg. distance between (exp): 435.5 vs. 459.4
  avg. distance between (yok): 319.9 vs. 316.4
training 2
  avg. time between [s]: 5.9 vs. 6.6
  avg. distance between (exp): 328.4 vs. 395.8
  avg. distance between (yok): 175.8 vs. 205.7
training 3
  avg. time between [s]: 4.4 vs. 5.0
  avg. distance between (exp): 268.5 vs. 282.9
  avg. distance between (yok): 119.2 vs. 136.0

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 11.6 vs. 8.9
  avg. time between [s] (yok): 21.3 vs. nan
  avg. distance between (exp): 528.3 vs. 454.9
  avg. distance between (yok): 686.9 vs. nan
training 2
  avg. time between [s] (exp): 9.0 vs. 7.4
  avg. time between [s] (yok): 23.2 vs. nan
  avg. distance between (exp): 510.4 vs. 450.4
  avg. distance between (yok): 704.3 vs. nan
training 3
  avg. time between [s] (exp): 5.4 vs. 6.4
  avg. time between [s] (yok): 19.3 vs. nan
  avg. distance between (exp): 321.3 vs. 364.6
  avg. distance between (yok): 565.3 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.5, 6.3, stop fraction: 0.47, 0.30
  yok: avg. speed bottom [mm/s]: 2.6, 3.9, stop fraction: 0.61, 0.48
training 2
  exp: avg. speed bottom [mm/s]: 6.2, 7.4, stop fraction: 0.32, 0.24
  yok: avg. speed bottom [mm/s]: 5.1, 3.8, stop fraction: 0.35, 0.51
training 3
  exp: avg. speed bottom [mm/s]: 5.7, 7.0, stop fraction: 0.37, 0.24
  yok: avg. speed bottom [mm/s]: 5.4, 3.9, stop fraction: 0.32, 0.50

rewards per distance traveled [m⁻¹]
training 1
  exp: 11.82, 17.61, 15.88, 21.21, 21.43
  yok: 9.87, 10.91, 13.33, 12.92, 15.55
training 2
  exp: 16.25, 18.07, 17.27, 19.79, 20.83
  yok: 10.53, 14.79, 9.30, 11.82, 14.75
training 3
  exp: 24.98, 22.60, 18.91, 25.06, 18.58
  yok: 14.53, 15.41, 13.81, 11.02, 13.58

=== analyzing c1__2025-07-09__12-47-17.avi, fly 2 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=344,y=90,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=344,y=90,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=344,y=90,r=10)

processing trajectories...
exp fly
  lost: number frames: 1122 (1.04%), sequence length: avg: 1.8, max: 9
    during "on" (2786 frames, 2 per "on" cmd): 2 (0.07%)
    interpolating...
  long (>30) jumps: 192, suspicious: 0 (0.0%)
  total calculated rewards during training: 1091
    for zero-width border: 1173 (+7.5%)
      compared with actual ones: only calc.: 118, only actual: 342
  total control rewards during trainings 1, 2, and 3: 2766
yok fly
  lost: number frames: 479 (0.44%), sequence length: avg: 1.6, max: 13
    during "on" (2786 frames, 2 per "on" cmd): 30 (1.08%)
    interpolating...
  long (>30) jumps: 15, suspicious: 0 (0.0%)
  total calculated rewards during training: 329
  total control rewards during trainings 1, 2, and 3: 826

total rewards training: 1404, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 88, 88, 73, 92, 83
  calc. exp: 77, 67, 61, 76, 70
  ctrl. exp: 162, 164, 155, 166, 147
    PI: -0.36, -0.42, -0.44, -0.37, -0.35
  calc. yok: 7, 17, 14, 14, 7
  ctrl. yok: 18, 40, 41, 38, 27
    PI: -0.44, -0.40, -0.49, -0.46, -0.59
training 2
  actual: 75, 89, 75, 70, 85
  calc. exp: 57, 70, 62, 53, 60
  ctrl. exp: 160, 174, 159, 158, 151
    PI: -0.47, -0.43, -0.44, -0.50, -0.43
  calc. yok: 15, 22, 23, 18, 24
  ctrl. yok: 41, 46, 41, 55, 63
    PI: -0.46, -0.35, -0.28, -0.51, -0.45
training 3
  actual: 87, 74, 96, 40, 60
  calc. exp: 64, 49, 81, 32, 44
  ctrl. exp: 191, 118, 173, 133, 131
    PI: -0.50, -0.41, -0.36, -0.61, -0.50
  calc. yok: 21, 19, 25, 24, 30
  ctrl. yok: 56, 40, 65, 70, 60
    PI: -0.45, -0.36, -0.44, -0.49, -0.33

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 379.9, 334.5, 368.1, 323.4, 431.7
  yok: 87.3, 98.5, 180.9, 132.7, 147.3
training 2
  exp: 503.9, 401.4, 488.9, 506.5, 388.0
  yok: 186.9, 182.5, 245.9, 367.7, 278.9
training 3
  exp: 361.3, 354.5, 306.4, 842.2, 494.9
  yok: 179.9, 263.4, 219.1, 670.9, 378.1

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (11), 3, 5, 0, 5, 0
  calc. yok: (3), 4, 5, 6, 1, 6
training 2
  calc. exp: (19), 4, 4, 3, 1, 2
  calc. yok: (6), 6, 4, 1, 1, 3
training 3
  calc. exp: (30), 9, 1, 8, 2, 4
  calc. yok: (8), 8, 1, 4, 4, 2

reward PI by post bucket (3 min)
training 1
  exp: -0.62, -0.41, nan, -0.38, nan
  yok: -0.60, -0.33, -0.40, nan, -0.37
training 2
  exp: -0.58, -0.47, -0.57, -0.86, -0.64
  yok: -0.37, -0.47, -0.86, -0.80, -0.57
training 3
  exp: -0.33, -0.90, -0.38, -0.82, -0.58
  yok: -0.48, -0.83, -0.72, -0.53, -0.60

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 6.5 vs. 7.9
  avg. distance between (exp): 362.6 vs. 434.8
  avg. distance between (yok): 88.2 vs. 175.5
training 2
  avg. time between [s]: 8.5 vs. 7.0
  avg. distance between (exp): 534.6 vs. 435.7
  avg. distance between (yok): 226.4 vs. 205.4
training 3
  avg. time between [s]: 6.9 vs. 7.6
  avg. distance between (exp): 366.6 vs. 341.4
  avg. distance between (yok): 200.8 vs. 243.8

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 7.6 vs. 10.2
  avg. time between [s] (yok): nan vs. nan
  avg. distance between (exp): 422.7 vs. 545.0
  avg. distance between (yok): nan vs. nan
training 2
  avg. time between [s] (exp): 10.4 vs. 8.3
  avg. time between [s] (yok): 29.5 vs. nan
  avg. distance between (exp): 639.6 vs. 496.2
  avg. distance between (yok): 967.3 vs. nan
training 3
  avg. time between [s] (exp): 10.7 vs. 8.6
  avg. time between [s] (yok): 23.5 vs. nan
  avg. distance between (exp): 524.8 vs. 446.7
  avg. distance between (yok): 903.7 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.8, 7.0, stop fraction: 0.44, 0.28
  yok: avg. speed bottom [mm/s]: 3.3, 2.6, stop fraction: 0.49, 0.61
training 2
  exp: avg. speed bottom [mm/s]: 5.1, 7.4, stop fraction: 0.38, 0.25
  yok: avg. speed bottom [mm/s]: 6.1, 4.1, stop fraction: 0.25, 0.46
training 3
  exp: avg. speed bottom [mm/s]: 7.4, 6.2, stop fraction: 0.22, 0.32
  yok: avg. speed bottom [mm/s]: 7.0, 4.6, stop fraction: 0.20, 0.43

rewards per distance traveled [m⁻¹]
training 1
  exp: 18.62, 16.24, 15.99, 19.54, 15.89
  yok: 7.40, 11.65, 7.43, 8.08, 4.54
training 2
  exp: 12.23, 15.78, 13.85, 11.99, 14.89
  yok: 8.68, 10.77, 10.20, 5.59, 8.31
training 3
  exp: 16.19, 14.47, 21.82, 7.73, 11.77
  yok: 10.44, 7.48, 9.28, 7.22, 10.17

=== analyzing c1__2025-07-09__12-47-17.avi, fly 3 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=490,y=90,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=490,y=90,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=490,y=90,r=10)

processing trajectories...
exp fly
  lost: number frames: 2266 (2.10%), sequence length: avg: 2.0, max: 23
    during "on" (1495 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 85, suspicious: 0 (0.0%)
  total calculated rewards during training: 620
    for zero-width border: 645 (+4.0%)
      compared with actual ones: only calc.: 48, only actual: 149
  total control rewards during trainings 1, 2, and 3: 1594
yok fly
  lost: number frames: 1030 (0.96%), sequence length: avg: 1.7, max: 80
    during "on" (1495 frames, 2 per "on" cmd): 25 (1.67%)
    interpolating...
  long (>30) jumps: 6, suspicious: 0 (0.0%)
  total calculated rewards during training: 481
  total control rewards during trainings 1, 2, and 3: 1249

total rewards training: 746, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 25, 35, 10, 39, 30
  calc. exp: 24, 31, 11, 35, 26
  ctrl. exp: 50, 81, 35, 76, 63
    PI: -0.35, -0.45, -0.52, -0.37, -0.42
  calc. yok: 20, 20, 21, 19, 17
  ctrl. yok: 41, 52, 44, 46, 48
    PI: -0.34, -0.44, -0.35, -0.42, -0.48
training 2
  actual: 34, 44, 48, 45, 56
  calc. exp: 27, 37, 40, 40, 48
  ctrl. exp: 85, 96, 93, 86, 111
    PI: -0.52, -0.44, -0.40, -0.37, -0.40
  calc. yok: 34, 31, 34, 28, 35
  ctrl. yok: 82, 74, 72, 77, 65
    PI: -0.41, -0.41, -0.36, -0.47, -0.30
training 3
  actual: 61, 51, 46, 38, 49
  calc. exp: 48, 39, 38, 27, 42
  ctrl. exp: 118, 109, 99, 102, 113
    PI: -0.42, -0.47, -0.45, -0.58, -0.46
  calc. yok: 30, 17, 36, 29, 19
  ctrl. yok: 87, 54, 96, 89, 73
    PI: -0.49, -0.52, -0.45, -0.51, -0.59

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 647.2, 480.4, 1639.4, 466.0, 717.4
  yok: 414.3, 365.7, 1074.6, 312.0, 416.8
training 2
  exp: 739.3, 623.5, 560.2, 661.7, 529.7
  yok: 695.3, 442.5, 362.2, 471.1, 325.0
training 3
  exp: 467.5, 640.7, 619.4, 976.6, 670.3
  yok: 336.4, 305.7, 433.3, 549.6, 413.6

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (11), 1, 3, 1, 0, 1
  calc. yok: (6), 2, 4, 8, 6, 4
training 2
  calc. exp: (10), 1, 4, 6, 2, 1
  calc. yok: (15), 6, 4, 3, 4, 4
training 3
  calc. exp: (9), 3, 1, 2, 6, 1
  calc. yok: (11), 5, 11, 6, 4, 5

reward PI by post bucket (3 min)
training 1
  exp: -0.82, -0.40, nan, nan, nan
  yok: -0.64, -0.56, -0.16, -0.25, -0.20
training 2
  exp: -0.89, -0.38, -0.33, nan, -0.80
  yok: -0.43, -0.47, -0.65, -0.27, -0.56
training 3
  exp: -0.54, nan, -0.71, -0.29, nan
  yok: -0.62, -0.33, -0.40, -0.56, -0.33

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 22.9 vs. nan
  avg. distance between (exp): 691.7 vs. nan
  avg. distance between (yok): 478.4 vs. nan
training 2
  avg. time between [s]: 14.6 vs. 12.2
  avg. distance between (exp): 682.4 vs. 616.3
  avg. distance between (yok): 524.7 vs. 402.0
training 3
  avg. time between [s]: 10.1 vs. 14.1
  avg. distance between (exp): 524.5 vs. 794.7
  avg. distance between (yok): 309.2 vs. 492.8

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 23.6 vs. nan
  avg. time between [s] (yok): 30.6 vs. nan
  avg. distance between (exp): 724.4 vs. nan
  avg. distance between (yok): 656.2 vs. nan
training 2
  avg. time between [s] (exp): 17.4 vs. 13.1
  avg. time between [s] (yok): 18.0 vs. 17.7
  avg. distance between (exp): 820.4 vs. 670.1
  avg. distance between (yok): 641.3 vs. 587.8
training 3
  avg. time between [s] (exp): 14.8 vs. 16.4
  avg. time between [s] (yok): 21.4 vs. nan
  avg. distance between (exp): 786.5 vs. 941.7
  avg. distance between (yok): 697.7 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 2.9, 4.2, stop fraction: 0.54, 0.49
  yok: avg. speed bottom [mm/s]: 1.2, 2.9, stop fraction: 0.82, 0.51
training 2
  exp: avg. speed bottom [mm/s]: 5.5, 6.2, stop fraction: 0.33, 0.35
  yok: avg. speed bottom [mm/s]: 2.7, 4.3, stop fraction: 0.55, 0.34
training 3
  exp: avg. speed bottom [mm/s]: 6.9, 6.9, stop fraction: 0.24, 0.30
  yok: avg. speed bottom [mm/s]: 3.5, 4.2, stop fraction: 0.44, 0.33

rewards per distance traveled [m⁻¹]
training 1
  exp: 11.99, 15.17, 4.49, 13.32, 8.87
  yok: 15.62, 12.75, 13.37, 10.67, 10.27
training 2
  exp: 8.72, 10.36, 10.28, 10.96, 12.90
  yok: 11.68, 12.22, 14.32, 10.66, 15.25
training 3
  exp: 13.66, 9.31, 9.83, 5.98, 10.06
  yok: 11.84, 8.39, 13.61, 11.35, 7.39

=== analyzing c1__2025-07-09__12-47-17.avi, fly 4 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=636,y=90,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=636,y=90,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=636,y=90,r=10)

processing trajectories...
exp fly
  lost: number frames: 3543 (3.28%), sequence length: avg: 1.9, max: 15
    during "on" (2383 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 38, suspicious: 1 (2.6%)
  total calculated rewards during training: 1051
    for zero-width border: 1160 (+10.4%)
      compared with actual ones: only calc.: 163, only actual: 195
  total control rewards during trainings 1, 2, and 3: 2093
yok fly
  lost: number frames: 2685 (2.48%), sequence length: avg: 2.1, max: 39
    during "on" (2383 frames, 2 per "on" cmd): 99 (4.15%)
    interpolating...
  long (>30) jumps: 3, suspicious: 0 (0.0%)
  total calculated rewards during training: 486
  total control rewards during trainings 1, 2, and 3: 1129

total rewards training: 1191, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 22, 30, 66, 79, 86
  calc. exp: 18, 28, 62, 68, 78
  ctrl. exp: 50, 81, 109, 144, 151
    PI: -0.47, -0.49, -0.27, -0.36, -0.32
  calc. yok: 8, 22, 16, 28, 25
  ctrl. yok: 28, 33, 46, 60, 59
    PI: -0.56, -0.20, -0.48, -0.36, -0.40
training 2
  actual: 75, 99, 85, 108, 97
  calc. exp: 66, 82, 73, 96, 83
  ctrl. exp: 149, 127, 156, 122, 131
    PI: -0.39, -0.22, -0.36, -0.12, -0.22
  calc. yok: 15, 44, 18, 30, 22
  ctrl. yok: 42, 74, 63, 82, 69
    PI: -0.47, -0.25, -0.56, -0.46, -0.52
training 3
  actual: 40, 40, 66, 58, 48
  calc. exp: 36, 35, 67, 52, 41
  ctrl. exp: 104, 87, 95, 111, 106
    PI: -0.49, -0.43, -0.17, -0.36, -0.44
  calc. yok: 31, 31, 26, 39, 36
  ctrl. yok: 70, 69, 65, 77, 73
    PI: -0.39, -0.38, -0.43, -0.33, -0.34

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 631.7, 713.2, 321.6, 277.5, 261.3
  yok: 413.2, 317.9, 177.9, 176.3, 161.4
training 2
  exp: 355.4, 221.6, 296.3, 236.9, 244.0
  yok: 190.0, 191.9, 204.7, 181.9, 196.7
training 3
  exp: 763.9, 722.0, 369.8, 489.5, 617.8
  yok: 438.5, 435.0, 232.3, 345.1, 402.2

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (13), 6, 6, 10, 3, 6
  calc. yok: (18), 6, 2, 8, 6, 4
training 2
  calc. exp: (13), 8, 5, 3, 1, 2
  calc. yok: (11), 4, 1, 8, 6, 5
training 3
  calc. exp: (15), 7, 2, 7, 6, 4
  calc. yok: (7), 7, 5, 3, 3, 4

reward PI by post bucket (3 min)
training 1
  exp: -0.56, -0.52, -0.38, -0.50, -0.33
  yok: -0.54, -0.75, -0.33, -0.37, -0.53
training 2
  exp: -0.54, -0.52, -0.50, nan, nan
  yok: -0.65, -0.87, -0.41, -0.25, -0.33
training 3
  exp: -0.58, -0.81, -0.42, -0.56, -0.69
  yok: -0.36, -0.64, -0.54, -0.50, -0.56

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 16.6 vs. 8.0
  avg. distance between (exp): 510.7 vs. 303.3
  avg. distance between (yok): 265.2 vs. 192.8
training 2
  avg. time between [s]: 7.6 vs. 6.5
  avg. distance between (exp): 331.6 vs. 269.6
  avg. distance between (yok): 190.4 vs. 204.4
training 3
  avg. time between [s]: 13.3 vs. 10.5
  avg. distance between (exp): 651.6 vs. 485.7
  avg. distance between (yok): 421.5 vs. 295.9

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 17.4 vs. 8.1
  avg. time between [s] (yok): 30.1 vs. nan
  avg. distance between (exp): 536.8 vs. 319.2
  avg. distance between (yok): 597.5 vs. nan
training 2
  avg. time between [s] (exp): 9.0 vs. 7.3
  avg. time between [s] (yok): 23.1 vs. nan
  avg. distance between (exp): 374.3 vs. 315.6
  avg. distance between (yok): 668.3 vs. nan
training 3
  avg. time between [s] (exp): 13.6 vs. 11.3
  avg. time between [s] (yok): 20.0 vs. nan
  avg. distance between (exp): 657.4 vs. 515.9
  avg. distance between (yok): 588.8 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 0.7, 4.5, stop fraction: 0.95, 0.45
  yok: avg. speed bottom [mm/s]: 1.5, 2.7, stop fraction: 0.75, 0.60
training 2
  exp: avg. speed bottom [mm/s]: 6.3, 5.2, stop fraction: 0.30, 0.39
  yok: avg. speed bottom [mm/s]: 3.2, 3.9, stop fraction: 0.53, 0.46
training 3
  exp: avg. speed bottom [mm/s]: 8.2, 5.9, stop fraction: 0.17, 0.34
  yok: avg. speed bottom [mm/s]: 4.1, 3.9, stop fraction: 0.42, 0.44

rewards per distance traveled [m⁻¹]
training 1
  exp: 10.50, 10.87, 23.61, 24.05, 26.04
  yok: 7.14, 19.16, 10.95, 15.77, 13.73
training 2
  exp: 19.60, 29.90, 22.36, 30.07, 28.27
  yok: 8.42, 18.54, 8.26, 12.25, 9.31
training 3
  exp: 9.02, 9.68, 22.41, 15.07, 11.21
  yok: 13.40, 13.99, 13.26, 15.91, 14.91

=== analyzing c1__2025-07-09__12-47-17.avi, fly 5 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=52,y=269,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=52,y=269,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=52,y=269,r=10)

processing trajectories...
exp fly
  lost: number frames: 4658 (4.31%), sequence length: avg: 2.0, max: 43
    during "on" (2202 frames, 2 per "on" cmd): 2 (0.09%)
    interpolating...
  long (>30) jumps: 174, suspicious: 0 (0.0%)
  total calculated rewards during training: 859
    for zero-width border: 915 (+6.5%)
      compared with actual ones: only calc.: 89, only actual: 277
  total control rewards during trainings 1, 2, and 3: 2341
yok fly
  lost: number frames: 12723 (11.77%) *** bad ***

total rewards training: 1106, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 63, 58, 74, 91, 57
  calc. exp: 52, 41, 60, 74, 44
  ctrl. exp: 139, 114, 131, 171, 136
    PI: -0.46, -0.47, -0.37, -0.40, -0.51
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 2
  actual: 54, 73, 33, 77, 59
  calc. exp: 46, 55, 26, 51, 40
  ctrl. exp: 115, 156, 92, 130, 125
    PI: -0.43, -0.48, -0.56, -0.44, -0.52
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad
training 3
  actual: 51, 41, 52, 66, 55
  calc. exp: 39, 29, 37, 56, 46
  ctrl. exp: 114, 86, 129, 140, 129
    PI: -0.49, -0.50, -0.55, -0.43, -0.47
  calc. yok: trajectory bad
  ctrl. yok: trajectory bad
    PI: trajectory bad

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 481.0, 575.4, 438.7, 388.4, 610.8
  yok: trajectory bad
training 2
  exp: 726.2, 525.2, 1079.6, 451.6, 563.3
  yok: trajectory bad
training 3
  exp: 643.6, 852.3, 642.2, 476.9, 560.3
  yok: trajectory bad

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (11), 4, 1, 7, 2, 1
  calc. yok: trajectory bad
training 2
  calc. exp: (15), 4, 1, 3, 4, 2
  calc. yok: trajectory bad
training 3
  calc. exp: (17), 1, 4, 10, 11, 2
  calc. yok: trajectory bad

reward PI by post bucket (3 min)
training 1
  exp: -0.58, -0.88, -0.36, nan, -0.88
  yok: trajectory bad
training 2
  exp: -0.43, -0.80, -0.45, -0.56, nan
  yok: trajectory bad
training 3
  exp: -0.86, -0.69, -0.35, -0.37, -0.67
  yok: trajectory bad

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 8.8 vs. 9.5
  avg. distance between (exp): 464.3 vs. 522.1
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s]: 10.0 vs. 11.6
  avg. distance between (exp): 664.0 vs. 680.0
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s]: 13.1 vs. 10.0
  avg. distance between (exp): 768.6 vs. 554.1
  avg. distance between (yok): trajectory bad

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 12.3 vs. 9.4
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 660.4 vs. 513.7
  avg. distance between (yok): trajectory bad
training 2
  avg. time between [s] (exp): 11.7 vs. 15.7
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 767.7 vs. 905.5
  avg. distance between (yok): trajectory bad
training 3
  avg. time between [s] (exp): 17.5 vs. 12.0
  avg. time between [s] (yok): trajectory bad
  avg. distance between (exp): 1025.7 vs. 646.9
  avg. distance between (yok): trajectory bad

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 7.0, 7.2, stop fraction: 0.23, 0.28
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 2
  exp: avg. speed bottom [mm/s]: 7.7, 7.5, stop fraction: 0.22, 0.26
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad
training 3
  exp: avg. speed bottom [mm/s]: 6.7, 6.9, stop fraction: 0.27, 0.25
  yok: avg. speed bottom [mm/s]: trajectory bad, stop fraction: trajectory bad

rewards per distance traveled [m⁻¹]
training 1
  exp: 13.81, 9.85, 15.12, 16.40, 9.45
  yok: trajectory bad
training 2
  exp: 9.51, 11.41, 6.00, 11.91, 9.42
  yok: trajectory bad
training 3
  exp: 9.63, 6.30, 8.59, 14.12, 11.48
  yok: trajectory bad

=== analyzing c1__2025-07-09__12-47-17.avi, fly 6 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=198,y=269,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=198,y=269,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=198,y=269,r=10)

processing trajectories...
exp fly
  lost: number frames: 1752 (1.62%), sequence length: avg: 1.8, max: 39
    during "on" (2073 frames, 2 per "on" cmd): 23 (1.11%)
    interpolating...
  long (>30) jumps: 45, suspicious: 0 (0.0%)
  total calculated rewards during training: 884
    for zero-width border: 941 (+6.4%)
      compared with actual ones: only calc.: 74, only actual: 169
  total control rewards during trainings 1, 2, and 3: 1915
yok fly
  lost: number frames: 1564 (1.45%), sequence length: avg: 2.2, max: 15
    during "on" (2073 frames, 2 per "on" cmd): 28 (1.35%)
    interpolating...
  long (>30) jumps: 119, suspicious: 0 (0.0%)
  total calculated rewards during training: 797
  total control rewards during trainings 1, 2, and 3: 2190

total rewards training: 1036, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 53, 40, 58, 31, 38
  calc. exp: 49, 32, 57, 31, 33
  ctrl. exp: 74, 76, 87, 84, 85
    PI: -0.20, -0.41, -0.21, -0.46, -0.44
  calc. yok: 36, 32, 34, 43, 52
  ctrl. yok: 77, 91, 108, 142, 131
    PI: -0.36, -0.48, -0.52, -0.54, -0.43
training 2
  actual: 56, 58, 66, 71, 76
  calc. exp: 50, 47, 54, 56, 63
  ctrl. exp: 105, 104, 127, 122, 145
    PI: -0.35, -0.38, -0.40, -0.37, -0.39
  calc. yok: 45, 44, 45, 40, 50
  ctrl. yok: 121, 117, 132, 130, 137
    PI: -0.46, -0.45, -0.49, -0.53, -0.47
training 3
  actual: 70, 56, 73, 46, 63
  calc. exp: 59, 48, 65, 40, 53
  ctrl. exp: 139, 107, 120, 100, 105
    PI: -0.40, -0.38, -0.30, -0.43, -0.33
  calc. yok: 56, 54, 57, 26, 40
  ctrl. yok: 145, 141, 145, 89, 136
    PI: -0.44, -0.45, -0.44, -0.55, -0.55

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 345.2, 477.2, 322.9, 694.3, 622.0
  yok: 415.0, 562.1, 438.5, 896.2, 745.5
training 2
  exp: 478.6, 391.6, 438.0, 426.6, 425.9
  yok: 547.6, 474.1, 472.0, 424.9, 385.1
training 3
  exp: 410.6, 430.4, 303.1, 388.8, 352.2
  yok: 391.2, 481.2, 385.5, 380.0, 418.5

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (15), 2, 3, 1, 2, 1
  calc. yok: (9), 13, 12, 7, 7, 7
training 2
  calc. exp: (5), 5, 0, 6, 4, 2
  calc. yok: (26), 17, 12, 12, 8, 8
training 3
  calc. exp: (17), 3, 1, 5, 9, 4
  calc. yok: (19), 17, 10, 11, 12, 10

reward PI by post bucket (3 min)
training 1
  exp: -0.76, -0.57, -0.80, nan, -0.87
  yok: -0.47, -0.31, -0.63, -0.53, -0.66
training 2
  exp: -0.33, nan, -0.37, -0.60, nan
  yok: -0.49, -0.38, -0.51, -0.56, -0.65
training 3
  exp: -0.45, nan, -0.29, -0.10, -0.53
  yok: -0.45, -0.58, -0.57, -0.48, -0.49

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 12.6 vs. 15.5
  avg. distance between (exp): 404.9 vs. 549.0
  avg. distance between (yok): 486.1 vs. 732.6
training 2
  avg. time between [s]: 10.6 vs. 8.8
  avg. distance between (exp): 447.9 vs. 446.7
  avg. distance between (yok): 547.7 vs. 441.7
training 3
  avg. time between [s]: 10.4 vs. 8.3
  avg. distance between (exp): 461.9 vs. 312.8
  avg. distance between (yok): 480.3 vs. 385.3

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 13.6 vs. 16.2
  avg. time between [s] (yok): 18.0 vs. 12.8
  avg. distance between (exp): 438.2 vs. 593.8
  avg. distance between (yok): 720.7 vs. 622.3
training 2
  avg. time between [s] (exp): 12.4 vs. 9.8
  avg. time between [s] (yok): 13.8 vs. 12.7
  avg. distance between (exp): 547.5 vs. 488.1
  avg. distance between (yok): 709.1 vs. 638.7
training 3
  avg. time between [s] (exp): 11.2 vs. 11.6
  avg. time between [s] (yok): 10.4 vs. 15.3
  avg. distance between (exp): 505.8 vs. 392.9
  avg. distance between (yok): 477.1 vs. 642.9

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.0, 4.5, stop fraction: 0.43, 0.48
  yok: avg. speed bottom [mm/s]: 4.5, 5.6, stop fraction: 0.35, 0.31
training 2
  exp: avg. speed bottom [mm/s]: 5.8, 6.2, stop fraction: 0.34, 0.36
  yok: avg. speed bottom [mm/s]: 7.1, 6.4, stop fraction: 0.21, 0.26
training 3
  exp: avg. speed bottom [mm/s]: 5.6, 5.1, stop fraction: 0.40, 0.44
  yok: avg. speed bottom [mm/s]: 7.1, 5.6, stop fraction: 0.19, 0.33

rewards per distance traveled [m⁻¹]
training 1
  exp: 21.64, 13.03, 24.32, 11.27, 11.04
  yok: 13.26, 10.81, 10.67, 11.51, 14.57
training 2
  exp: 15.11, 15.15, 14.69, 14.92, 15.82
  yok: 11.90, 11.80, 11.41, 10.81, 13.86
training 3
  exp: 16.46, 16.05, 23.86, 16.12, 18.04
  yok: 16.42, 16.03, 16.28, 10.00, 11.55

=== analyzing c1__2025-07-09__12-47-17.avi, fly 7 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=344,y=269,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=344,y=269,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=344,y=269,r=10)

processing trajectories...
exp fly
  lost: number frames: 1789 (1.65%), sequence length: avg: 1.9, max: 47
    during "on" (3218 frames, 2 per "on" cmd): 99 (3.08%)
    interpolating...
  long (>30) jumps: 12, suspicious: 0 (0.0%)
  total calculated rewards during training: 1488
    for zero-width border: 1545 (+3.8%)
      compared with actual ones: only calc.: 93, only actual: 152
  total control rewards during trainings 1, 2, and 3: 2224
yok fly
  lost: number frames: 2473 (2.29%), sequence length: avg: 2.9, max: 63
    during "on" (3218 frames, 2 per "on" cmd): 60 (1.86%)
    interpolating...
  long (>30) jumps: 89, suspicious: 1 (1.1%)
  total calculated rewards during training: 696
  total control rewards during trainings 1, 2, and 3: 2049

total rewards training: 1612, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 59, 71, 53, 50, 62
  calc. exp: 58, 64, 50, 45, 55
  ctrl. exp: 100, 106, 90, 102, 89
    PI: -0.27, -0.25, -0.29, -0.39, -0.24
  calc. yok: 40, 31, 53, 25, 37
  ctrl. yok: 134, 115, 118, 124, 110
    PI: -0.54, -0.58, -0.38, -0.66, -0.50
training 2
  actual: 106, 97, 87, 105, 116
  calc. exp: 92, 85, 82, 99, 105
  ctrl. exp: 120, 138, 131, 148, 125
    PI: -0.13, -0.24, -0.23, -0.20, -0.09
  calc. yok: 42, 38, 53, 45, 38
  ctrl. yok: 132, 116, 139, 121, 111
    PI: -0.52, -0.51, -0.45, -0.46, -0.49
training 3
  actual: 161, 148, 120, 46, 90
  calc. exp: 148, 140, 103, 45, 90
  ctrl. exp: 161, 192, 171, 94, 109
    PI: -0.04, -0.16, -0.25, -0.35, -0.10
  calc. yok: 31, 35, 28, 45, 23
  ctrl. yok: 85, 109, 96, 131, 82
    PI: -0.47, -0.51, -0.55, -0.49, -0.56

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 331.0, 296.9, 412.5, 434.3, 397.5
  yok: 516.9, 347.8, 453.0, 486.0, 413.3
training 2
  exp: 226.8, 279.0, 311.3, 251.0, 186.4
  yok: 286.8, 268.0, 322.0, 281.2, 202.8
training 3
  exp: 168.9, 170.3, 208.0, 572.6, 231.9
  yok: 131.1, 163.3, 210.8, 570.2, 268.3

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (29), 8, 2, 5, 4, 0
  calc. yok: (6), 6, 4, 2, 5, 3
training 2
  calc. exp: (24), 6, 6, 5, 3, 2
  calc. yok: (18), 12, 8, 3, 3, 5
training 3
  calc. exp: (20), 11, 4, 9, 5, 2
  calc. yok: (7), 8, 5, 6, 1, 3

reward PI by post bucket (3 min)
training 1
  exp: -0.36, -0.71, -0.17, -0.53, nan
  yok: -0.47, -0.53, nan, -0.23, -0.45
training 2
  exp: -0.40, -0.45, -0.44, -0.68, nan
  yok: -0.41, -0.47, -0.62, -0.40, -0.23
training 3
  exp: -0.44, -0.58, -0.33, -0.47, -0.60
  yok: -0.70, -0.70, -0.33, -0.85, -0.57

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 9.6 vs. 10.5
  avg. distance between (exp): 328.7 vs. 386.1
  avg. distance between (yok): 449.3 vs. 443.5
training 2
  avg. time between [s]: 4.2 vs. 7.7
  avg. distance between (exp): 181.4 vs. 337.0
  avg. distance between (yok): 216.2 vs. 359.1
training 3
  avg. time between [s]: 3.8 vs. 4.2
  avg. distance between (exp): 178.6 vs. 182.4
  avg. distance between (yok): 133.4 vs. 178.1

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 10.3 vs. 10.9
  avg. time between [s] (yok): 15.6 vs. 15.0
  avg. distance between (exp): 354.7 vs. 411.8
  avg. distance between (yok): 707.6 vs. 650.0
training 2
  avg. time between [s] (exp): 6.3 vs. 8.6
  avg. time between [s] (yok): 14.3 vs. 14.0
  avg. distance between (exp): 263.1 vs. 394.3
  avg. distance between (yok): 700.7 vs. 648.6
training 3
  avg. time between [s] (exp): 4.0 vs. 4.6
  avg. time between [s] (yok): 20.1 vs. nan
  avg. distance between (exp): 183.1 vs. 203.4
  avg. distance between (yok): 811.0 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.7, 4.7, stop fraction: 0.39, 0.35
  yok: avg. speed bottom [mm/s]: 5.4, 5.6, stop fraction: 0.27, 0.34
training 2
  exp: avg. speed bottom [mm/s]: 4.5, 5.3, stop fraction: 0.35, 0.30
  yok: avg. speed bottom [mm/s]: 5.2, 5.7, stop fraction: 0.36, 0.33
training 3
  exp: avg. speed bottom [mm/s]: 5.3, 5.3, stop fraction: 0.32, 0.31
  yok: avg. speed bottom [mm/s]: 6.4, 5.1, stop fraction: 0.29, 0.36

rewards per distance traveled [m⁻¹]
training 1
  exp: 22.97, 24.00, 17.62, 16.05, 18.24
  yok: 10.19, 10.01, 16.95, 7.91, 11.81
training 2
  exp: 30.10, 25.35, 24.54, 30.16, 36.92
  yok: 10.86, 11.70, 15.41, 12.29, 12.53
training 3
  exp: 44.01, 43.09, 33.43, 14.16, 33.18
  yok: 11.82, 11.16, 8.96, 14.20, 7.49

=== analyzing c1__2025-07-09__12-47-17.avi, fly 8 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=490,y=269,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=490,y=269,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=490,y=269,r=10)

processing trajectories...
exp fly
  lost: number frames: 1378 (1.27%), sequence length: avg: 1.5, max: 36
    during "on" (2909 frames, 2 per "on" cmd): 3 (0.10%)
    interpolating...
  long (>30) jumps: 33, suspicious: 0 (0.0%)
  total calculated rewards during training: 1325
    for zero-width border: 1484 (+12.0%)
      compared with actual ones: only calc.: 227, only actual: 192
  total control rewards during trainings 1, 2, and 3: 2190
yok fly
  lost: number frames: 1407 (1.30%), sequence length: avg: 1.9, max: 10
    during "on" (2909 frames, 2 per "on" cmd): 31 (1.07%)
    interpolating...
  long (>30) jumps: 18, suspicious: 0 (0.0%)
  total calculated rewards during training: 552
  total control rewards during trainings 1, 2, and 3: 1644

total rewards training: 1454, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 37, 61, 69, 78, 82
  calc. exp: 31, 62, 61, 70, 78
  ctrl. exp: 91, 95, 88, 136, 127
    PI: -0.49, -0.21, -0.18, -0.32, -0.24
  calc. yok: 14, 34, 28, 39, 35
  ctrl. yok: 62, 90, 80, 88, 100
    PI: -0.63, -0.45, -0.48, -0.39, -0.48
training 2
  actual: 91, 113, 65, 81, 109
  calc. exp: 89, 103, 56, 70, 98
  ctrl. exp: 111, 144, 108, 106, 133
    PI: -0.11, -0.17, -0.32, -0.20, -0.15
  calc. yok: 33, 44, 33, 38, 40
  ctrl. yok: 100, 94, 110, 114, 99
    PI: -0.50, -0.36, -0.54, -0.50, -0.42
training 3
  actual: 95, 81, 53, 112, 102
  calc. exp: 88, 69, 45, 100, 94
  ctrl. exp: 137, 135, 105, 148, 151
    PI: -0.22, -0.32, -0.40, -0.19, -0.23
  calc. yok: 32, 34, 14, 22, 29
  ctrl. yok: 100, 86, 64, 89, 100
    PI: -0.52, -0.43, -0.64, -0.60, -0.55

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 486.6, 301.0, 209.5, 278.6, 256.9
  yok: 372.5, 269.8, 251.6, 288.1, 284.4
training 2
  exp: 243.4, 185.6, 368.6, 303.0, 211.8
  yok: 255.7, 209.3, 404.5, 365.3, 246.8
training 3
  exp: 288.7, 313.3, 482.7, 227.0, 247.1
  yok: 256.3, 317.7, 480.6, 206.0, 227.2

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (30), 8, 3, 3, 4, 4
  calc. yok: (8), 0, 2, 2, 1, 0
training 2
  calc. exp: (18), 10, 9, 1, 3, 6
  calc. yok: (4), 5, 3, 3, 1, 2
training 3
  calc. exp: (17), 11, 6, 4, 3, 4
  calc. yok: (6), 2, 3, 5, 0, 4

reward PI by post bucket (3 min)
training 1
  exp: -0.62, -0.62, -0.40, -0.60, -0.62
  yok: nan, nan, -0.60, nan, nan
training 2
  exp: -0.43, -0.36, nan, -0.62, -0.54
  yok: -0.62, -0.71, -0.54, nan, -0.60
training 3
  exp: -0.55, -0.68, -0.58, -0.78, -0.58
  yok: nan, -0.68, -0.17, nan, -0.62

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 13.9 vs. 6.7
  avg. distance between (exp): 397.5 vs. 232.8
  avg. distance between (yok): 342.7 vs. 239.7
training 2
  avg. time between [s]: 6.7 vs. 4.9
  avg. distance between (exp): 253.6 vs. 161.3
  avg. distance between (yok): 261.6 vs. 199.4
training 3
  avg. time between [s]: 6.1 vs. 7.6
  avg. distance between (exp): 283.6 vs. 311.8
  avg. distance between (yok): 254.3 vs. 325.3

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 13.9 vs. 7.5
  avg. time between [s] (yok): 21.4 vs. nan
  avg. distance between (exp): 397.5 vs. 258.9
  avg. distance between (yok): 625.9 vs. nan
training 2
  avg. time between [s] (exp): 6.8 vs. 5.5
  avg. time between [s] (yok): 15.8 vs. 15.8
  avg. distance between (exp): 255.8 vs. 192.5
  avg. distance between (yok): 653.8 vs. 723.8
training 3
  avg. time between [s] (exp): 6.9 vs. 11.0
  avg. time between [s] (yok): 23.5 vs. nan
  avg. distance between (exp): 311.0 vs. 472.2
  avg. distance between (yok): 974.3 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.2, 4.1, stop fraction: 0.43, 0.47
  yok: avg. speed bottom [mm/s]: 2.2, 4.2, stop fraction: 0.66, 0.48
training 2
  exp: avg. speed bottom [mm/s]: 5.6, 4.9, stop fraction: 0.35, 0.39
  yok: avg. speed bottom [mm/s]: 5.3, 5.3, stop fraction: 0.39, 0.39
training 3
  exp: avg. speed bottom [mm/s]: 6.2, 5.6, stop fraction: 0.31, 0.37
  yok: avg. speed bottom [mm/s]: 5.5, 5.0, stop fraction: 0.38, 0.42

rewards per distance traveled [m⁻¹]
training 1
  exp: 13.48, 27.55, 29.84, 25.26, 28.37
  yok: 7.88, 16.25, 11.44, 14.08, 11.84
training 2
  exp: 32.63, 38.97, 19.02, 23.24, 34.60
  yok: 11.51, 14.91, 10.20, 10.48, 12.14
training 3
  exp: 25.65, 22.07, 14.41, 32.03, 29.75
  yok: 10.51, 10.66, 4.31, 7.76, 10.04

=== analyzing c1__2025-07-09__12-47-17.avi, fly 9 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=636,y=269,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=636,y=269,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=636,y=269,r=10)

processing trajectories...
exp fly
  lost: number frames: 4194 (3.88%), sequence length: avg: 2.3, max: 119
    during "on" (2782 frames, 2 per "on" cmd): 3 (0.11%)
    interpolating...
  long (>30) jumps: 304, suspicious: 1 (0.3%)
  total calculated rewards during training: 1076
    for zero-width border: 1186 (+10.2%)
      compared with actual ones: only calc.: 152, only actual: 353
  total control rewards during trainings 1, 2, and 3: 2575
yok fly
  lost: number frames: 6272 (5.80%), sequence length: avg: 2.5, max: 100
    during "on" (2782 frames, 2 per "on" cmd): 77 (2.77%)
    interpolating...
  long (>30) jumps: 16, suspicious: 0 (0.0%)
  total calculated rewards during training: 527
  total control rewards during trainings 1, 2, and 3: 1465

total rewards training: 1396, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 84, 47, 83, 93, 73
  calc. exp: 70, 31, 63, 67, 61
  ctrl. exp: 150, 118, 147, 172, 151
    PI: -0.36, -0.58, -0.40, -0.44, -0.42
  calc. yok: 21, 15, 24, 28, 25
  ctrl. yok: 63, 46, 52, 72, 70
    PI: -0.50, -0.51, -0.37, -0.44, -0.47
training 2
  actual: 65, 66, 61, 90, 100
  calc. exp: 46, 50, 40, 61, 81
  ctrl. exp: 166, 152, 141, 162, 141
    PI: -0.57, -0.50, -0.56, -0.45, -0.27
  calc. yok: 30, 35, 30, 36, 64
  ctrl. yok: 80, 102, 88, 100, 113
    PI: -0.45, -0.49, -0.49, -0.47, -0.28
training 3
  actual: 86, 99, 67, 86, 89
  calc. exp: 69, 76, 50, 64, 80
  ctrl. exp: 156, 171, 126, 125, 110
    PI: -0.39, -0.38, -0.43, -0.32, -0.16
  calc. yok: 16, 26, 36, 28, 28
  ctrl. yok: 88, 73, 87, 90, 93
    PI: -0.69, -0.47, -0.41, -0.53, -0.54

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 397.8, 624.7, 413.6, 401.8, 515.6
  yok: 194.8, 335.9, 232.1, 237.8, 311.7
training 2
  exp: 426.1, 530.4, 634.9, 409.3, 333.2
  yok: 380.0, 362.2, 453.2, 286.9, 278.1
training 3
  exp: 381.7, 283.8, 312.7, 285.2, 244.5
  yok: 272.9, 249.8, 273.6, 258.1, 284.8

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (3), 2, 3, 1, 6, 2
  calc. yok: (5), 4, 4, 1, 2, 1
training 2
  calc. exp: (9), 4, 2, 2, 1, 1
  calc. yok: (7), 2, 2, 2, 5, 3
training 3
  calc. exp: (12), 11, 4, 4, 9, 1
  calc. yok: (10), 7, 2, 2, 0, 1

reward PI by post bucket (3 min)
training 1
  exp: nan, -0.45, nan, -0.37, nan
  yok: nan, -0.67, -0.82, nan, nan
training 2
  exp: -0.38, -0.67, nan, -0.88, -0.80
  yok: -0.76, -0.60, nan, -0.60, -0.45
training 3
  exp: -0.40, -0.58, -0.56, -0.10, nan
  yok: -0.39, nan, -0.71, nan, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 7.6 vs. 9.1
  avg. distance between (exp): 429.2 vs. 529.9
  avg. distance between (yok): 223.6 vs. 271.9
training 2
  avg. time between [s]: 9.2 vs. 9.4
  avg. distance between (exp): 481.8 vs. 590.8
  avg. distance between (yok): 403.0 vs. 414.6
training 3
  avg. time between [s]: 6.6 vs. 6.6
  avg. distance between (exp): 362.4 vs. 307.2
  avg. distance between (yok): 252.1 vs. 282.2

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 11.0 vs. 10.1
  avg. time between [s] (yok): 27.1 vs. nan
  avg. distance between (exp): 627.5 vs. 591.2
  avg. distance between (yok): 873.3 vs. nan
training 2
  avg. time between [s] (exp): 12.5 vs. 11.8
  avg. time between [s] (yok): 18.6 vs. 12.1
  avg. distance between (exp): 681.7 vs. 746.9
  avg. distance between (yok): 820.3 vs. 557.0
training 3
  avg. time between [s] (exp): 7.3 vs. 10.9
  avg. time between [s] (yok): 21.7 vs. nan
  avg. distance between (exp): 397.6 vs. 465.9
  avg. distance between (yok): 847.4 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.7, 7.2, stop fraction: 0.40, 0.34
  yok: avg. speed bottom [mm/s]: 3.1, 4.3, stop fraction: 0.49, 0.43
training 2
  exp: avg. speed bottom [mm/s]: 3.5, 7.2, stop fraction: 0.61, 0.31
  yok: avg. speed bottom [mm/s]: 5.2, 5.6, stop fraction: 0.35, 0.31
training 3
  exp: avg. speed bottom [mm/s]: 8.5, 5.4, stop fraction: 0.16, 0.37
  yok: avg. speed bottom [mm/s]: 6.4, 5.1, stop fraction: 0.22, 0.36

rewards per distance traveled [m⁻¹]
training 1
  exp: 16.26, 7.71, 14.54, 14.71, 13.08
  yok: 9.85, 7.07, 9.97, 10.38, 8.77
training 2
  exp: 12.53, 11.58, 8.40, 13.19, 19.52
  yok: 8.98, 11.81, 8.80, 11.03, 18.45
training 3
  exp: 16.84, 22.03, 16.53, 21.05, 30.16
  yok: 5.47, 8.59, 12.14, 10.04, 9.06

=== analyzing c1__2025-07-09__12-47-17.avi, fly 10 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 11 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 12 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 13 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 14 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 15 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 16 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 17 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 18 ===

yoked control

=== analyzing c1__2025-07-09__12-47-17.avi, fly 19 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 0 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=81,y=96,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=81,y=96,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=81,y=96,r=10)

processing trajectories...
exp fly
  lost: number frames: 4563 (4.22%), sequence length: avg: 2.6, max: 168
    during "on" (1659 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 95, suspicious: 0 (0.0%)
  total calculated rewards during training: 677
    for zero-width border: 729 (+7.7%)
      compared with actual ones: only calc.: 73, only actual: 172
  total control rewards during trainings 1, 2, and 3: 1567
yok fly
  lost: number frames: 3294 (3.05%), sequence length: avg: 1.8, max: 35
    during "on" (1659 frames, 2 per "on" cmd): 76 (4.58%)
    interpolating...
  long (>30) jumps: 215, suspicious: 1 (0.5%)
  total calculated rewards during training: 583
  total control rewards during trainings 1, 2, and 3: 1828

total rewards training: 830, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 22, 31, 52, 29, 63
  calc. exp: 17, 27, 46, 24, 54
  ctrl. exp: 42, 43, 82, 71, 108
    PI: -0.42, -0.23, -0.28, -0.49, -0.33
  calc. yok: 23, 15, 32, 26, 40
  ctrl. yok: 60, 64, 88, 84, 107
    PI: -0.45, -0.62, -0.47, -0.53, -0.46
training 2
  actual: 73, 31, 33, 58, 66
  calc. exp: 64, 23, 25, 42, 51
  ctrl. exp: 119, 80, 63, 116, 129
    PI: -0.30, -0.55, -0.43, -0.47, -0.43
  calc. yok: 39, 30, 33, 46, 38
  ctrl. yok: 133, 109, 120, 136, 140
    PI: -0.55, -0.57, -0.57, -0.49, -0.57
training 3
  actual: 48, 44, 58, 26, 78
  calc. exp: 37, 39, 50, 20, 61
  ctrl. exp: 102, 87, 109, 62, 110
    PI: -0.47, -0.38, -0.37, -0.51, -0.29
  calc. yok: 46, 60, 36, 35, 0
  ctrl. yok: 148, 146, 146, 107, 0
    PI: -0.53, -0.42, -0.60, -0.51, nan

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 704.1, 518.0, 363.5, 695.3, 379.9
  yok: 908.9, 836.1, 539.7, 1061.3, 584.3
training 2
  exp: 385.4, 675.0, 566.1, 487.0, 464.0
  yok: 514.8, 1021.6, 816.0, 691.0, 602.1
training 3
  exp: 580.9, 627.7, 514.8, 761.3, 391.4
  yok: 973.1, 1033.6, 656.5, 907.8, 23.3

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (12), 3, 1, 1, 0, 2
  calc. yok: (7), 8, 8, 1, 0, 2
training 2
  calc. exp: (4), 3, 2, 4, 3, 0
  calc. yok: (10), 4, 13, 7, 7, 9
training 3
  calc. exp: (12), 5, 2, 5, 3, 2
  calc. yok: (0), 0, 0, 0, 0, 0

reward PI by post bucket (3 min)
training 1
  exp: -0.54, -0.82, nan, nan, nan
  yok: -0.56, -0.38, -0.90, nan, -0.69
training 2
  exp: nan, -0.71, -0.53, -0.54, nan
  yok: -0.72, -0.26, -0.60, -0.58, -0.44
training 3
  exp: -0.52, nan, -0.41, nan, nan
  yok: nan, nan, nan, nan, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 17.3 vs. 12.8
  avg. distance between (exp): 526.6 vs. 484.8
  avg. distance between (yok): 782.9 vs. 787.9
training 2
  avg. time between [s]: 10.2 vs. 13.9
  avg. distance between (exp): 463.4 vs. 639.9
  avg. distance between (yok): 659.6 vs. 976.2
training 3
  avg. time between [s]: 12.5 vs. 12.9
  avg. distance between (exp): 586.8 vs. 577.3
  avg. distance between (yok): 956.7 vs. 609.7

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 20.2 vs. 12.4
  avg. time between [s] (yok): 24.3 vs. nan
  avg. distance between (exp): 627.9 vs. 499.2
  avg. distance between (yok): 1222.6 vs. nan
training 2
  avg. time between [s] (exp): 14.6 vs. 14.5
  avg. time between [s] (yok): 17.4 vs. 15.4
  avg. distance between (exp): 676.3 vs. 702.4
  avg. distance between (yok): 1173.2 vs. 1100.9
training 3
  avg. time between [s] (exp): 14.9 vs. 14.6
  avg. time between [s] (yok): 10.9 vs. nan
  avg. distance between (exp): 697.7 vs. 647.0
  avg. distance between (yok): 841.9 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 3.2, 4.4, stop fraction: 0.54, 0.51
  yok: avg. speed bottom [mm/s]: 3.3, 6.9, stop fraction: 0.54, 0.28
training 2
  exp: avg. speed bottom [mm/s]: 3.0, 5.7, stop fraction: 0.61, 0.40
  yok: avg. speed bottom [mm/s]: 7.3, 8.8, stop fraction: 0.22, 0.18
training 3
  exp: avg. speed bottom [mm/s]: 6.0, 5.6, stop fraction: 0.37, 0.42
  yok: avg. speed bottom [mm/s]: 9.6, 5.6, stop fraction: 0.12, 0.46

rewards per distance traveled [m⁻¹]
training 1
  exp: 8.28, 13.13, 17.53, 8.90, 18.07
  yok: 8.26, 4.51, 7.73, 5.74, 8.82
training 2
  exp: 17.95, 7.11, 8.09, 11.69, 13.08
  yok: 8.20, 6.02, 6.30, 9.03, 7.05
training 3
  exp: 10.69, 11.47, 13.16, 7.76, 16.42
  yok: 7.89, 10.77, 7.44, 11.80, 0.00

=== analyzing c2__2025-07-09__12-47-22.avi, fly 1 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=227,y=96,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=227,y=96,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=227,y=96,r=10)

processing trajectories...
exp fly
  lost: number frames: 744 (0.69%), sequence length: avg: 1.5, max: 18
    during "on" (1782 frames, 2 per "on" cmd): 1 (0.06%)
    interpolating...
  long (>30) jumps: 59, suspicious: 1 (1.7%)
  total calculated rewards during training: 750
    for zero-width border: 864 (+15.2%)
      compared with actual ones: only calc.: 149, only actual: 175
  total control rewards during trainings 1, 2, and 3: 1791
yok fly
  lost: number frames: 94 (0.09%), sequence length: avg: 1.1, max: 3
    during "on" (1782 frames, 2 per "on" cmd): 7 (0.39%)
    interpolating...
  long (>30) jumps: 43, suspicious: 0 (0.0%)
  total calculated rewards during training: 635
  total control rewards during trainings 1, 2, and 3: 1697

total rewards training: 898, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 58, 70, 56, 40, 60
  calc. exp: 47, 62, 49, 37, 49
  ctrl. exp: 96, 97, 105, 89, 112
    PI: -0.34, -0.22, -0.36, -0.41, -0.39
  calc. yok: 38, 28, 29, 27, 34
  ctrl. yok: 85, 65, 77, 69, 91
    PI: -0.38, -0.40, -0.45, -0.44, -0.46
training 2
  actual: 75, 50, 61, 70, 43
  calc. exp: 59, 38, 46, 58, 42
  ctrl. exp: 146, 113, 105, 151, 119
    PI: -0.42, -0.50, -0.39, -0.44, -0.48
  calc. yok: 38, 35, 34, 40, 33
  ctrl. yok: 114, 104, 95, 113, 95
    PI: -0.50, -0.50, -0.47, -0.48, -0.48
training 3
  actual: 58, 50, 56, 26, 10
  calc. exp: 46, 41, 49, 25, 9
  ctrl. exp: 104, 103, 86, 84, 21
    PI: -0.39, -0.43, -0.27, -0.54, -0.40
  calc. yok: 35, 53, 23, 62, 27
  ctrl. yok: 112, 102, 94, 122, 94
    PI: -0.52, -0.32, -0.61, -0.33, -0.55

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 381.2, 355.3, 365.9, 505.3, 415.0
  yok: 425.1, 327.6, 347.9, 548.2, 446.5
training 2
  exp: 349.4, 490.2, 318.9, 328.1, 465.4
  yok: 412.4, 635.7, 451.2, 491.4, 706.5
training 3
  exp: 354.2, 379.2, 305.2, 479.4, 453.0
  yok: 542.3, 657.4, 524.3, 1171.6, 2283.9

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (15), 8, 2, 3, 0, 2
  calc. yok: (9), 5, 0, 0, 3, 1
training 2
  calc. exp: (18), 5, 6, 10, 3, 2
  calc. yok: (13), 6, 3, 3, 7, 1
training 3
  calc. exp: (0), 0, 0, 0, 0, 0
  calc. yok: (3), 3, 6, 5, 0, 3

reward PI by post bucket (3 min)
training 1
  exp: -0.33, -0.80, -0.54, nan, -0.64
  yok: -0.50, -1.00, nan, -0.54, nan
training 2
  exp: -0.74, -0.48, -0.35, -0.73, -0.69
  yok: -0.54, -0.73, -0.57, -0.55, -0.86
training 3
  exp: nan, nan, nan, nan, nan
  yok: nan, nan, nan, nan, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 9.4 vs. 11.7
  avg. distance between (exp): 362.6 vs. 471.8
  avg. distance between (yok): 384.1 vs. 473.7
training 2
  avg. time between [s]: 8.4 vs. 10.8
  avg. distance between (exp): 369.0 vs. 407.3
  avg. distance between (yok): 441.1 vs. 556.1
training 3
  avg. time between [s]: 11.1 vs. 17.1
  avg. distance between (exp): 381.0 vs. 382.3
  avg. distance between (yok): 607.8 vs. 934.7

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 11.0 vs. 13.1
  avg. time between [s] (yok): 18.6 vs. nan
  avg. distance between (exp): 439.3 vs. 522.9
  avg. distance between (yok): 757.2 vs. nan
training 2
  avg. time between [s] (exp): 12.2 vs. 11.7
  avg. time between [s] (yok): 15.1 vs. 17.9
  avg. distance between (exp): 521.7 vs. 436.6
  avg. distance between (yok): 817.5 vs. 979.3
training 3
  avg. time between [s] (exp): 14.2 vs. nan
  avg. time between [s] (yok): 16.1 vs. 13.9
  avg. distance between (exp): 464.8 vs. nan
  avg. distance between (yok): 869.1 vs. 766.7

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.7, 5.0, stop fraction: 0.36, 0.39
  yok: avg. speed bottom [mm/s]: 3.7, 5.3, stop fraction: 0.45, 0.35
training 2
  exp: avg. speed bottom [mm/s]: 6.5, 5.0, stop fraction: 0.27, 0.39
  yok: avg. speed bottom [mm/s]: 6.4, 6.7, stop fraction: 0.25, 0.24
training 3
  exp: avg. speed bottom [mm/s]: 6.3, 2.8, stop fraction: 0.27, 0.64
  yok: avg. speed bottom [mm/s]: 7.8, 6.7, stop fraction: 0.17, 0.25

rewards per distance traveled [m⁻¹]
training 1
  exp: 16.77, 19.63, 16.68, 12.85, 16.10
  yok: 12.16, 9.37, 10.45, 8.43, 10.26
training 2
  exp: 18.20, 12.21, 17.25, 20.47, 15.20
  yok: 9.97, 8.71, 9.04, 9.43, 7.91
training 3
  exp: 17.51, 17.61, 22.83, 14.94, 12.00
  yok: 8.70, 13.14, 6.08, 14.56, 6.63

=== analyzing c2__2025-07-09__12-47-22.avi, fly 2 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=373,y=96,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=373,y=96,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=373,y=96,r=10)

processing trajectories...
exp fly
  lost: number frames: 1292 (1.19%), sequence length: avg: 2.2, max: 145
    during "on" (2383 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 126, suspicious: 0 (0.0%)
  total calculated rewards during training: 990
    for zero-width border: 1075 (+8.6%)
      compared with actual ones: only calc.: 125, only actual: 242
  total control rewards during trainings 1, 2, and 3: 2301
yok fly
  lost: number frames: 8 (0.01%), sequence length: avg: 1.0, max: 1
    during "on" (2383 frames, 2 per "on" cmd): 1 (0.04%)
    interpolating...
  long (>30) jumps: 39, suspicious: 0 (0.0%)
  total calculated rewards during training: 731
  total control rewards during trainings 1, 2, and 3: 1934

total rewards training: 1197, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 81, 77, 86, 37, 43
  calc. exp: 75, 66, 71, 34, 38
  ctrl. exp: 146, 120, 119, 73, 77
    PI: -0.32, -0.29, -0.25, -0.36, -0.34
  calc. yok: 39, 40, 50, 33, 29
  ctrl. yok: 91, 100, 113, 69, 89
    PI: -0.40, -0.43, -0.39, -0.35, -0.51
training 2
  actual: 71, 71, 59, 87, 69
  calc. exp: 63, 62, 53, 66, 48
  ctrl. exp: 131, 150, 95, 138, 156
    PI: -0.35, -0.42, -0.28, -0.35, -0.53
  calc. yok: 36, 37, 47, 37, 38
  ctrl. yok: 103, 111, 119, 105, 110
    PI: -0.48, -0.50, -0.43, -0.48, -0.49
training 3
  actual: 111, 43, 70, 57, 47
  calc. exp: 93, 34, 61, 45, 37
  ctrl. exp: 188, 99, 132, 131, 108
    PI: -0.34, -0.49, -0.37, -0.49, -0.49
  calc. yok: 38, 48, 52, 38, 36
  ctrl. yok: 116, 136, 147, 106, 96
    PI: -0.51, -0.48, -0.48, -0.47, -0.45

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 344.3, 358.7, 318.1, 473.3, 388.0
  yok: 268.7, 355.9, 319.7, 483.6, 479.3
training 2
  exp: 415.7, 449.3, 524.4, 332.4, 483.6
  yok: 465.6, 499.4, 602.6, 372.2, 444.0
training 3
  exp: 288.3, 570.5, 369.8, 568.1, 652.7
  yok: 314.7, 618.8, 465.0, 579.0, 655.9

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (14), 3, 1, 3, 4, 3
  calc. yok: (8), 3, 4, 1, 3, 2
training 2
  calc. exp: (10), 10, 6, 1, 3, 4
  calc. yok: (18), 2, 3, 7, 1, 5
training 3
  calc. exp: (22), 4, 5, 0, 3, 2
  calc. yok: (16), 3, 4, 6, 4, 5

reward PI by post bucket (3 min)
training 1
  exp: -0.77, nan, -0.45, nan, nan
  yok: -0.73, -0.47, nan, -0.67, -0.69
training 2
  exp: -0.39, -0.50, nan, -0.62, -0.47
  yok: -0.78, -0.65, -0.52, nan, -0.47
training 3
  exp: -0.56, -0.38, nan, -0.50, -0.80
  yok: -0.70, -0.56, -0.45, -0.58, -0.57

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 7.7 vs. 7.3
  avg. distance between (exp): 358.6 vs. 346.1
  avg. distance between (yok): 293.5 vs. 337.1
training 2
  avg. time between [s]: 8.8 vs. 9.0
  avg. distance between (exp): 443.3 vs. 465.3
  avg. distance between (yok): 500.9 vs. 524.1
training 3
  avg. time between [s]: 5.4 vs. 10.5
  avg. distance between (exp): 292.5 vs. 536.4
  avg. distance between (yok): 323.5 vs. 606.1

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 8.5 vs. 9.0
  avg. time between [s] (yok): 15.2 vs. 15.6
  avg. distance between (exp): 396.1 vs. 414.1
  avg. distance between (yok): 638.4 vs. 734.2
training 2
  avg. time between [s] (exp): 10.6 vs. 8.8
  avg. time between [s] (yok): 16.5 vs. 14.4
  avg. distance between (exp): 540.2 vs. 450.5
  avg. distance between (yok): 946.2 vs. 816.3
training 3
  avg. time between [s] (exp): 7.0 vs. 12.9
  avg. time between [s] (yok): 13.8 vs. 14.2
  avg. distance between (exp): 372.0 vs. 665.9
  avg. distance between (yok): 796.6 vs. 803.6

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 2.3, 5.4, stop fraction: 0.64, 0.42
  yok: avg. speed bottom [mm/s]: 3.3, 5.7, stop fraction: 0.54, 0.30
training 2
  exp: avg. speed bottom [mm/s]: 3.9, 6.6, stop fraction: 0.56, 0.30
  yok: avg. speed bottom [mm/s]: 5.6, 7.1, stop fraction: 0.32, 0.21
training 3
  exp: avg. speed bottom [mm/s]: 7.9, 6.4, stop fraction: 0.20, 0.31
  yok: avg. speed bottom [mm/s]: 6.2, 7.0, stop fraction: 0.31, 0.21

rewards per distance traveled [m⁻¹]
training 1
  exp: 21.83, 19.26, 20.80, 12.49, 15.69
  yok: 14.55, 11.63, 14.51, 10.12, 8.13
training 2
  exp: 17.32, 15.99, 14.09, 18.23, 11.29
  yok: 8.76, 8.57, 10.87, 8.99, 9.47
training 3
  exp: 23.50, 8.76, 16.81, 11.31, 9.71
  yok: 8.78, 11.49, 11.24, 9.40, 9.48

=== analyzing c2__2025-07-09__12-47-22.avi, fly 3 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=519,y=96,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=519,y=96,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=519,y=96,r=10)

processing trajectories...
exp fly
  no trajectory
yok fly
  no trajectory

*** skipping analysis ***

=== analyzing c2__2025-07-09__12-47-22.avi, fly 4 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=665,y=96,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=665,y=96,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=665,y=96,r=10)

processing trajectories...
exp fly
  no trajectory
yok fly
  no trajectory

*** skipping analysis ***

=== analyzing c2__2025-07-09__12-47-22.avi, fly 5 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=81,y=275,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=81,y=275,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=81,y=275,r=10)

processing trajectories...
exp fly
  lost: number frames: 79 (0.07%), sequence length: avg: 2.0, max: 15
    during "on" (1819 frames, 2 per "on" cmd): 1 (0.05%)
    interpolating...
  long (>30) jumps: 82, suspicious: 0 (0.0%)
  total calculated rewards during training: 749
    for zero-width border: 830 (+10.8%)
      compared with actual ones: only calc.: 112, only actual: 185
  total control rewards during trainings 1, 2, and 3: 1654
yok fly
  lost: number frames: 3858 (3.57%), sequence length: avg: 2.8, max: 51
    during "on" (1819 frames, 2 per "on" cmd): 84 (4.62%)
    interpolating...
  long (>30) jumps: 5, suspicious: 0 (0.0%)
  total calculated rewards during training: 465
  total control rewards during trainings 1, 2, and 3: 1303

total rewards training: 918, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 12, 19, 34, 40, 54
  calc. exp: 10, 17, 32, 34, 43
  ctrl. exp: 45, 44, 57, 63, 96
    PI: -0.64, -0.44, -0.28, -0.30, -0.38
  calc. yok: 5, 21, 25, 17, 19
  ctrl. yok: 20, 53, 49, 57, 61
    PI: -0.60, -0.43, -0.32, -0.54, -0.53
training 2
  actual: 61, 46, 73, 50, 82
  calc. exp: 49, 33, 61, 48, 67
  ctrl. exp: 99, 106, 123, 115, 103
    PI: -0.34, -0.53, -0.34, -0.41, -0.21
  calc. yok: 31, 32, 17, 25, 28
  ctrl. yok: 87, 71, 63, 73, 75
    PI: -0.47, -0.38, -0.57, -0.49, -0.46
training 3
  actual: 61, 59, 44, 92, 38
  calc. exp: 50, 47, 37, 68, 33
  ctrl. exp: 90, 122, 92, 137, 102
    PI: -0.29, -0.44, -0.43, -0.34, -0.51
  calc. yok: 19, 27, 38, 39, 44
  ctrl. yok: 87, 72, 95, 95, 105
    PI: -0.64, -0.45, -0.43, -0.42, -0.41

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 718.4, 472.0, 253.2, 382.2, 323.6
  yok: 553.9, 546.5, 247.2, 394.6, 322.4
training 2
  exp: 293.8, 366.0, 282.3, 437.0, 248.6
  yok: 334.5, 384.5, 275.4, 423.3, 249.6
training 3
  exp: 355.0, 391.6, 497.5, 239.1, 525.5
  yok: 392.5, 416.3, 581.7, 260.2, 716.3

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (12), 3, 1, 0, 1, 3
  calc. yok: (9), 5, 2, 0, 2, 1
training 2
  calc. exp: (16), 2, 2, 9, 5, 6
  calc. yok: (15), 7, 1, 3, 5, 4
training 3
  calc. exp: (8), 6, 6, 4, 6, 5
  calc. yok: (7), 7, 9, 4, 3, 2

reward PI by post bucket (3 min)
training 1
  exp: nan, nan, nan, nan, -0.54
  yok: -0.53, -0.60, nan, nan, nan
training 2
  exp: nan, -0.67, -0.10, -0.70, -0.20
  yok: -0.50, -0.83, -0.50, -0.33, -0.56
training 3
  exp: -0.69, -0.40, -0.50, -0.54, -0.64
  yok: -0.50, -0.36, -0.56, -0.57, nan

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 23.6 vs. nan
  avg. distance between (exp): 502.7 vs. nan
  avg. distance between (yok): 558.2 vs. nan
training 2
  avg. time between [s]: 9.4 vs. 11.1
  avg. distance between (exp): 322.8 vs. 376.3
  avg. distance between (yok): 352.1 vs. 397.5
training 3
  avg. time between [s]: 10.5 vs. 10.4
  avg. distance between (exp): 389.9 vs. 388.6
  avg. distance between (yok): 424.9 vs. 444.6

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 24.8 vs. nan
  avg. time between [s] (yok): 35.1 vs. nan
  avg. distance between (exp): 536.4 vs. nan
  avg. distance between (yok): 853.8 vs. nan
training 2
  avg. time between [s] (exp): 15.1 vs. 9.2
  avg. time between [s] (yok): 21.9 vs. nan
  avg. distance between (exp): 496.0 vs. 344.4
  avg. distance between (yok): 799.3 vs. nan
training 3
  avg. time between [s] (exp): 12.3 vs. 11.3
  avg. time between [s] (yok): 20.5 vs. nan
  avg. distance between (exp): 459.3 vs. 430.7
  avg. distance between (yok): 853.6 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 1.0, 2.8, stop fraction: 0.86, 0.62
  yok: avg. speed bottom [mm/s]: 0.8, 3.1, stop fraction: 0.89, 0.49
training 2
  exp: avg. speed bottom [mm/s]: 2.6, 4.4, stop fraction: 0.64, 0.44
  yok: avg. speed bottom [mm/s]: 2.7, 4.7, stop fraction: 0.59, 0.32
training 3
  exp: avg. speed bottom [mm/s]: 3.6, 4.6, stop fraction: 0.53, 0.41
  yok: avg. speed bottom [mm/s]: 4.7, 5.4, stop fraction: 0.34, 0.27

rewards per distance traveled [m⁻¹]
training 1
  exp: 7.48, 11.76, 20.50, 16.87, 19.43
  yok: 4.22, 11.53, 12.76, 8.23, 8.64
training 2
  exp: 20.50, 13.09, 23.97, 16.95, 26.00
  yok: 11.75, 11.41, 6.79, 9.09, 10.40
training 3
  exp: 18.75, 16.70, 13.39, 24.24, 12.82
  yok: 6.44, 9.01, 11.62, 12.78, 12.80

=== analyzing c2__2025-07-09__12-47-22.avi, fly 6 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=227,y=275,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=227,y=275,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=227,y=275,r=10)

processing trajectories...
exp fly
  lost: number frames: 371 (0.34%), sequence length: avg: 2.2, max: 53
    during "on" (2084 frames, 2 per "on" cmd): 0 (0.00%)
    interpolating...
  long (>30) jumps: 11, suspicious: 0 (0.0%)
  total calculated rewards during training: 1001
    for zero-width border: 1185 (+18.4%)
      compared with actual ones: only calc.: 254, only actual: 111
  total control rewards during trainings 1, 2, and 3: 1242
yok fly
  lost: number frames: 109 (0.10%), sequence length: avg: 1.3, max: 3
    during "on" (2084 frames, 2 per "on" cmd): 4 (0.19%)
    interpolating...
  long (>30) jumps: 26, suspicious: 0 (0.0%)
  total calculated rewards during training: 719
  total control rewards during trainings 1, 2, and 3: 1993

total rewards training: 1043, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 38, 39, 41, 39, 44
  calc. exp: 36, 41, 39, 38, 40
  ctrl. exp: 24, 48, 55, 56, 57
    PI: 0.20, -0.08, -0.17, -0.19, -0.18
  calc. yok: 47, 48, 35, 49, 25
  ctrl. yok: 111, 95, 120, 172, 119
    PI: -0.41, -0.33, -0.55, -0.56, -0.65
training 2
  actual: 73, 65, 55, 67, 65
  calc. exp: 66, 60, 53, 62, 63
  ctrl. exp: 79, 71, 85, 80, 77
    PI: -0.09, -0.08, -0.23, -0.13, -0.10
  calc. yok: 55, 49, 38, 30, 40
  ctrl. yok: 153, 118, 125, 92, 113
    PI: -0.47, -0.41, -0.53, -0.51, -0.48
training 3
  actual: 68, 42, 83, 68, 76
  calc. exp: 66, 40, 78, 63, 72
  ctrl. exp: 76, 85, 76, 106, 81
    PI: -0.07, -0.36, 0.01, -0.25, -0.06
  calc. yok: 40, 41, 41, 52, 39
  ctrl. yok: 105, 109, 88, 103, 86
    PI: -0.45, -0.45, -0.36, -0.33, -0.38

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 192.4, 237.7, 240.9, 260.2, 280.2
  yok: 537.8, 521.0, 480.5, 542.0, 423.0
training 2
  exp: 190.8, 220.0, 271.0, 211.6, 227.6
  yok: 274.5, 300.1, 335.6, 206.2, 279.5
training 3
  exp: 220.7, 296.0, 170.7, 223.4, 188.5
  yok: 226.9, 372.1, 202.0, 269.4, 197.2

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (33), 2, 6, 7, 3, 3
  calc. yok: (0), 8, 7, 6, 2, 9
training 2
  calc. exp: (9), 6, 3, 7, 2, 0
  calc. yok: (9), 4, 11, 8, 4, 0
training 3
  calc. exp: (21), 12, 6, 6, 2, 8
  calc. yok: (2), 7, 6, 4, 4, 3

reward PI by post bucket (3 min)
training 1
  exp: -0.76, -0.29, 0.00, -0.50, -0.40
  yok: -0.53, -0.58, -0.54, nan, -0.54
training 2
  exp: -0.45, -0.65, -0.12, nan, nan
  yok: -0.43, -0.52, -0.27, -0.33, nan
training 3
  exp: -0.39, -0.43, -0.25, -0.71, -0.41
  yok: -0.26, -0.33, -0.62, -0.38, -0.40

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 15.2 vs. 14.6
  avg. distance between (exp): 212.7 vs. 273.0
  avg. distance between (yok): 515.8 vs. 465.9
training 2
  avg. time between [s]: 8.5 vs. 9.8
  avg. distance between (exp): 197.7 vs. 248.8
  avg. distance between (yok): 286.6 vs. 308.8
training 3
  avg. time between [s]: 10.4 vs. 8.3
  avg. distance between (exp): 270.8 vs. 198.7
  avg. distance between (yok): 309.2 vs. 246.1

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 15.1 vs. 15.1
  avg. time between [s] (yok): 12.6 vs. 16.4
  avg. distance between (exp): 211.3 vs. 280.8
  avg. distance between (yok): 440.0 vs. 532.8
training 2
  avg. time between [s] (exp): 9.4 vs. 9.7
  avg. time between [s] (yok): 10.4 vs. 17.7
  avg. distance between (exp): 220.2 vs. 244.4
  avg. distance between (yok): 349.3 vs. 522.8
training 3
  avg. time between [s] (exp): 10.3 vs. 9.0
  avg. time between [s] (yok): 14.0 vs. 12.3
  avg. distance between (exp): 269.9 vs. 218.3
  avg. distance between (yok): 423.1 vs. 366.5

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 1.4, 2.1, stop fraction: 0.77, 0.64
  yok: avg. speed bottom [mm/s]: 2.9, 4.2, stop fraction: 0.56, 0.41
training 2
  exp: avg. speed bottom [mm/s]: 2.5, 3.0, stop fraction: 0.60, 0.51
  yok: avg. speed bottom [mm/s]: 4.5, 3.9, stop fraction: 0.45, 0.44
training 3
  exp: avg. speed bottom [mm/s]: 2.4, 3.1, stop fraction: 0.60, 0.52
  yok: avg. speed bottom [mm/s]: 2.3, 3.6, stop fraction: 0.76, 0.52

rewards per distance traveled [m⁻¹]
training 1
  exp: 39.84, 36.75, 32.57, 29.14, 26.67
  yok: 18.61, 19.55, 14.68, 19.05, 11.13
training 2
  exp: 38.47, 34.04, 28.01, 31.14, 33.75
  yok: 22.26, 20.48, 16.19, 15.26, 16.84
training 3
  exp: 33.76, 22.20, 44.60, 31.93, 40.41
  yok: 19.69, 16.99, 19.73, 21.94, 20.79

=== analyzing c2__2025-07-09__12-47-22.avi, fly 7 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=373,y=275,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=373,y=275,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=373,y=275,r=10)

processing trajectories...
exp fly
  lost: number frames: 1140 (1.05%), sequence length: avg: 1.7, max: 36
    during "on" (2562 frames, 2 per "on" cmd): 47 (1.83%)
    interpolating...
  long (>30) jumps: 58, suspicious: 0 (0.0%)
  total calculated rewards during training: 1122
    for zero-width border: 1237 (+10.2%)
      compared with actual ones: only calc.: 164, only actual: 204
  total control rewards during trainings 1, 2, and 3: 2567
yok fly
  lost: number frames: 1640 (1.52%), sequence length: avg: 4.5, max: 67
    during "on" (2562 frames, 2 per "on" cmd): 43 (1.68%)
    interpolating...
  long (>30) jumps: 9, suspicious: 0 (0.0%)
  total calculated rewards during training: 481
  total control rewards during trainings 1, 2, and 3: 1298

total rewards training: 1281, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 58, 77, 82, 54, 40
  calc. exp: 52, 71, 69, 51, 36
  ctrl. exp: 134, 157, 143, 140, 72
    PI: -0.44, -0.38, -0.35, -0.47, -0.33
  calc. yok: 16, 23, 33, 24, 30
  ctrl. yok: 63, 64, 67, 61, 89
    PI: -0.59, -0.47, -0.34, -0.44, -0.50
training 2
  actual: 68, 70, 78, 85, 106
  calc. exp: 60, 58, 73, 79, 87
  ctrl. exp: 156, 145, 163, 187, 174
    PI: -0.44, -0.43, -0.38, -0.41, -0.33
  calc. yok: 35, 28, 35, 17, 27
  ctrl. yok: 100, 73, 105, 75, 61
    PI: -0.48, -0.45, -0.50, -0.63, -0.39
training 3
  actual: 79, 72, 52, 55, 70
  calc. exp: 65, 62, 49, 44, 63
  ctrl. exp: 130, 151, 151, 114, 138
    PI: -0.33, -0.42, -0.51, -0.44, -0.37
  calc. yok: 26, 28, 26, 21, 25
  ctrl. yok: 78, 54, 65, 65, 55
    PI: -0.50, -0.32, -0.43, -0.51, -0.38

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 492.5, 346.0, 374.6, 534.9, 293.4
  yok: 266.1, 210.0, 217.1, 314.1, 339.9
training 2
  exp: 419.2, 392.6, 368.1, 339.1, 273.5
  yok: 243.8, 209.6, 194.8, 176.6, 133.7
training 3
  exp: 331.8, 379.5, 542.0, 425.3, 364.3
  yok: 183.3, 185.2, 287.1, 233.7, 173.4

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (20), 10, 1, 2, 3, 2
  calc. yok: (4), 6, 8, 6, 4, 8
training 2
  calc. exp: (24), 5, 8, 3, 2, 2
  calc. yok: (5), 3, 6, 6, 3, 3
training 3
  calc. exp: (20), 7, 14, 11, 5, 4
  calc. yok: (6), 7, 4, 2, 0, 2

reward PI by post bucket (3 min)
training 1
  exp: -0.39, -0.80, -0.60, -0.67, nan
  yok: -0.54, -0.33, -0.60, -0.38, -0.06
training 2
  exp: -0.68, -0.20, -0.50, -0.64, -0.71
  yok: -0.81, -0.54, -0.43, -0.76, -0.68
training 3
  exp: -0.53, -0.22, -0.39, -0.47, -0.53
  yok: -0.33, -0.27, nan, nan, -0.67

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 9.0 vs. 7.5
  avg. distance between (exp): 417.7 vs. 372.8
  avg. distance between (yok): 233.9 vs. 223.5
training 2
  avg. time between [s]: 10.0 vs. 6.6
  avg. distance between (exp): 475.3 vs. 322.7
  avg. distance between (yok): 273.8 vs. 166.2
training 3
  avg. time between [s]: 7.3 vs. 10.5
  avg. distance between (exp): 332.8 vs. 490.3
  avg. distance between (yok): 182.9 vs. 251.9

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 9.8 vs. 8.9
  avg. time between [s] (yok): 25.6 vs. nan
  avg. distance between (exp): 450.8 vs. 455.9
  avg. distance between (yok): 717.6 vs. nan
training 2
  avg. time between [s] (exp): 11.0 vs. 7.5
  avg. time between [s] (yok): 20.9 vs. nan
  avg. distance between (exp): 527.0 vs. 370.5
  avg. distance between (yok): 551.8 vs. nan
training 3
  avg. time between [s] (exp): 9.9 vs. 12.1
  avg. time between [s] (yok): 22.1 vs. nan
  avg. distance between (exp): 448.0 vs. 521.9
  avg. distance between (yok): 528.5 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.8, 5.2, stop fraction: 0.37, 0.42
  yok: avg. speed bottom [mm/s]: 1.6, 3.5, stop fraction: 0.79, 0.45
training 2
  exp: avg. speed bottom [mm/s]: 4.7, 6.1, stop fraction: 0.45, 0.33
  yok: avg. speed bottom [mm/s]: 3.4, 3.2, stop fraction: 0.50, 0.50
training 3
  exp: avg. speed bottom [mm/s]: 5.9, 5.5, stop fraction: 0.37, 0.39
  yok: avg. speed bottom [mm/s]: 3.6, 2.9, stop fraction: 0.47, 0.54

rewards per distance traveled [m⁻¹]
training 1
  exp: 14.61, 21.21, 18.19, 14.41, 21.42
  yok: 8.36, 11.33, 14.91, 11.57, 13.93
training 2
  exp: 16.98, 15.91, 20.07, 22.13, 24.04
  yok: 17.04, 14.54, 18.27, 9.13, 15.22
training 3
  exp: 19.45, 17.99, 14.33, 15.03, 19.18
  yok: 13.82, 16.51, 14.26, 13.27, 15.34

=== analyzing c2__2025-07-09__12-47-22.avi, fly 8 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=519,y=275,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=519,y=275,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=519,y=275,r=10)

processing trajectories...
exp fly
  lost: number frames: 239 (0.22%), sequence length: avg: 1.2, max: 4
    during "on" (2891 frames, 2 per "on" cmd): 2 (0.07%)
    interpolating...
  long (>30) jumps: 28, suspicious: 0 (0.0%)
  total calculated rewards during training: 1254
    for zero-width border: 1293 (+3.1%)
      compared with actual ones: only calc.: 56, only actual: 206
  total control rewards during trainings 1, 2, and 3: 2388
yok fly
  lost: number frames: 3041 (2.81%), sequence length: avg: 3.2, max: 25
    during "on" (2891 frames, 2 per "on" cmd): 88 (3.04%)
    interpolating...
  long (>30) jumps: 5, suspicious: 0 (0.0%)
  total calculated rewards during training: 543
  total control rewards during trainings 1, 2, and 3: 1365

total rewards training: 1443, non-training: 3

number rewards by sync bucket (10 min):
training 1
  actual: 34, 62, 53, 84, 46
  calc. exp: 30, 55, 52, 67, 37
  ctrl. exp: 59, 122, 101, 125, 83
    PI: -0.33, -0.38, -0.32, -0.30, -0.38
  calc. yok: 16, 33, 21, 29, 27
  ctrl. yok: 39, 60, 61, 56, 82
    PI: -0.42, -0.29, -0.49, -0.32, -0.50
training 2
  actual: 53, 65, 59, 69, 69
  calc. exp: 46, 56, 47, 56, 56
  ctrl. exp: 101, 126, 115, 124, 132
    PI: -0.37, -0.38, -0.42, -0.38, -0.40
  calc. yok: 41, 18, 33, 35, 35
  ctrl. yok: 94, 72, 85, 81, 101
    PI: -0.39, -0.60, -0.44, -0.40, -0.49
training 3
  actual: 95, 63, 130, 158, 150
  calc. exp: 79, 51, 116, 143, 136
  ctrl. exp: 165, 113, 200, 216, 187
    PI: -0.35, -0.38, -0.27, -0.20, -0.16
  calc. yok: 29, 30, 26, 18, 36
  ctrl. yok: 80, 89, 77, 56, 82
    PI: -0.47, -0.50, -0.50, -0.51, -0.39

average distance traveled between actual rewards by sync bucket:
training 1
  exp: 483.7, 365.9, 462.0, 311.9, 476.6
  yok: 287.3, 201.0, 263.6, 168.4, 326.7
training 2
  exp: 671.3, 531.4, 480.3, 399.7, 417.0
  yok: 394.1, 297.3, 321.8, 251.2, 268.9
training 3
  exp: 355.9, 536.4, 248.9, 204.3, 217.0
  yok: 201.7, 326.9, 139.0, 95.5, 121.5

positional PI (r*1.3) by post bucket (2 min):

number __calculated__ rewards by post bucket (3 min):
training 1  (values in parentheses are still training)
  calc. exp: (25), 0, 1, 1, 1, 3
  calc. yok: (13), 1, 4, 2, 2, 1
training 2
  calc. exp: (22), 1, 1, 2, 2, 3
  calc. yok: (9), 7, 8, 1, 3, 5
training 3
  calc. exp: (43), 5, 3, 1, 1, 2
  calc. yok: (3), 2, 1, 1, 0, 3

reward PI by post bucket (3 min)
training 1
  exp: nan, nan, nan, nan, nan
  yok: -0.83, -0.27, -0.67, nan, nan
training 2
  exp: nan, nan, nan, nan, nan
  yok: -0.40, -0.30, nan, -0.65, -0.41
training 3
  exp: -0.55, -0.40, nan, nan, nan
  yok: -0.71, nan, nan, nan, -0.45

by actual reward: (first 100 vs. next 100)
training 1
  avg. time between [s]: 12.2 vs. 10.1
  avg. distance between (exp): 439.6 vs. 442.5
  avg. distance between (yok): 249.2 vs. 245.8
training 2
  avg. time between [s]: 11.1 vs. 9.9
  avg. distance between (exp): 640.0 vs. 504.0
  avg. distance between (yok): 367.3 vs. 340.4
training 3
  avg. time between [s]: 6.3 vs. 8.0
  avg. distance between (exp): 357.1 vs. 451.1
  avg. distance between (yok): 192.9 vs. 292.0

by __calculated__ reward: (first 100 vs. next 100)
training 1
  avg. time between [s] (exp): 14.4 vs. 9.5
  avg. time between [s] (yok): 23.1 vs. nan
  avg. distance between (exp): 523.5 vs. 430.8
  avg. distance between (yok): 523.2 vs. nan
training 2
  avg. time between [s] (exp): 11.9 vs. 10.7
  avg. time between [s] (yok): 19.0 vs. 16.7
  avg. distance between (exp): 690.4 vs. 551.5
  avg. distance between (yok): 650.6 vs. 584.8
training 3
  avg. time between [s] (exp): 7.2 vs. 8.3
  avg. time between [s] (yok): 23.5 vs. nan
  avg. distance between (exp): 411.4 vs. 470.2
  avg. distance between (yok): 735.9 vs. nan

speed stats (with values for 10-min pre period first):
training 1
  exp: avg. speed bottom [mm/s]: 4.0, 5.2, stop fraction: 0.48, 0.45
  yok: avg. speed bottom [mm/s]: 1.8, 3.2, stop fraction: 0.70, 0.57
training 2
  exp: avg. speed bottom [mm/s]: 4.0, 6.7, stop fraction: 0.54, 0.30
  yok: avg. speed bottom [mm/s]: 3.8, 4.4, stop fraction: 0.49, 0.43
training 3
  exp: avg. speed bottom [mm/s]: 4.4, 6.9, stop fraction: 0.52, 0.27
  yok: avg. speed bottom [mm/s]: 3.7, 3.9, stop fraction: 0.51, 0.47

rewards per distance traveled [m⁻¹]
training 1
  exp: 13.35, 18.09, 16.29, 19.98, 12.62
  yok: 12.04, 19.58, 11.76, 15.81, 11.91
training 2
  exp: 10.50, 13.34, 12.65, 15.33, 13.95
  yok: 15.94, 7.68, 12.75, 14.76, 12.01
training 3
  exp: 18.92, 12.31, 27.11, 36.08, 34.19
  yok: 12.29, 11.93, 10.37, 9.73, 16.17

=== analyzing c2__2025-07-09__12-47-22.avi, fly 9 ===

  video length: 4.0h, frame rate: 7.5 fps, chamber type: HtL
  (pre: 15.1 min)
  training 1: 1.0h, center (post: 15 min) (circle x=665,y=275,r=10)
  training 2: 1.0h, center (post: 15.1 min) (circle x=665,y=275,r=10)
  training 3: 1.0h, center (post: 15 min) (circle x=665,y=275,r=10)

processing trajectories...
exp fly
  no trajectory
yok fly
  no trajectory

*** skipping analysis ***

=== analyzing c2__2025-07-09__12-47-22.avi, fly 10 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 11 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 12 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 13 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 14 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 15 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 16 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 17 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 18 ===

yoked control

=== analyzing c2__2025-07-09__12-47-22.avi, fly 19 ===

yoked control


=== all video analysis (27 videos) ===

total rewards training: 41937
writing imgs/trajectory_len_dist.png...

average time between actual rewards:
paired t-test -- training 1, first 100 vs. next 100:
  n = 25, means: 8.94, 8.01; t-test: p = 0.12972, t = 1.569
paired t-test -- first 100, training 1 vs. 2:
  n = 27, means: 9.99, 7.43; t-test: p = 0.00303, t = 3.269

average time between __calculated__ rewards:
paired t-test -- training 1, exp fly first 100 vs. yok fly first 100:
  n = 19, means: 12.7, 20.1; t-test: p = 0.00000, t = -7.223
paired t-test -- training 2, exp fly first 100 vs. yok fly first 100:
  n = 20, means: 10.1, 16.8; t-test: p = 0.00002, t = -5.701
paired t-test -- training 3, exp fly first 100 vs. yok fly first 100:
  n = 20, means: 9.76, 17; t-test: p = 0.00008, t = -4.972
paired t-test -- training 1, yok fly first 100 vs. yok fly next 100:
  n = 9, means: 13.9, 13.1; t-test: p = 0.42722, t = 0.836

average distance traveled between actual rewards:
paired t-test -- training 1, exp fly first 100 vs. yok fly first 100:
  n = 22, means: 364, 318; t-test: p = 0.20940, t = 1.295
paired t-test -- training 2, exp fly first 100 vs. yok fly first 100:
  n = 22, means: 344, 303; t-test: p = 0.14497, t = 1.514
paired t-test -- training 3, exp fly first 100 vs. yok fly first 100:
  n = 22, means: 320, 308; t-test: p = 0.74858, t = 0.325
paired t-test -- training 1, exp fly next 100 vs. yok fly next 100:
  n = 20, means: 340, 310; t-test: p = 0.38349, t = 0.892
paired t-test -- training 2, exp fly next 100 vs. yok fly next 100:
  n = 22, means: 340, 312; t-test: p = 0.36569, t = 0.925
paired t-test -- training 3, exp fly next 100 vs. yok fly next 100:
  n = 22, means: 328, 334; t-test: p = 0.87874, t = -0.154
paired t-test -- training 1, exp fly first 100 vs. exp fly next 100:
  n = 25, means: 335, 323; t-test: p = 0.52187, t = 0.650
paired t-test -- exp fly first 100, training 1 vs. 2:
  n = 27, means: 354, 331; t-test: p = 0.30041, t = 1.057

average distance traveled between __calculated__ rewards:
paired t-test -- training 1, exp fly first 100 vs. yok fly first 100:
  n = 19, means: 429, 661; t-test: p = 0.00000, t = -6.779
paired t-test -- training 2, exp fly first 100 vs. yok fly first 100:
  n = 20, means: 454, 676; t-test: p = 0.00004, t = -5.273
paired t-test -- training 3, exp fly first 100 vs. yok fly first 100:
  n = 20, means: 401, 660; t-test: p = 0.00008, t = -4.977
paired t-test -- training 1, yok fly first 100 vs. yok fly next 100:
  n = 9, means: 559, 532; t-test: p = 0.40407, t = 0.881

number actual rewards by sync bucket:
paired t-test -- training 1, first 10 min vs. next 10 min:
  n = 27, means: 71.3, 84.6; t-test: p = 0.00440, t = -3.119
paired t-test -- first 10 min, training 1 vs. 2:
  n = 27, means: 71.3, 95.9; t-test: p = 0.00031, t = -4.158

number __calculated__ rewards by sync bucket:
paired t-test -- training 1, exp fly first 10 min vs. yok fly first 10 min:
  n = 22, means: 59.9, 26.2; t-test: p = 0.00039, t = 4.209
paired t-test -- training 2, exp fly first 10 min vs. yok fly first 10 min:
  n = 22, means: 79, 36.8; t-test: p = 0.00027, t = 4.374
paired t-test -- training 3, exp fly first 10 min vs. yok fly first 10 min:
  n = 22, means: 81.4, 34.3; t-test: p = 0.00011, t = 4.732
paired t-test -- training 1, yok fly first 10 min vs. yok fly next 10 min:
  n = 22, means: 26.2, 30.3; t-test: p = 0.11990, t = -1.621

positional PI (r*1.3) by post bucket:
skipped

__calculated__ reward PI by sync bucket:
writing imgs/reward_pi__10_min_buckets.png...
paired t-test -- training 1, fly delta, bucket #1 vs. #5:
  n = 21, means: 0.139, 0.165; t-test: p = 0.47619, t = -0.726
paired t-test -- training 2, fly delta, bucket #1 vs. #5:
  n = 22, means: 0.121, 0.225; t-test: p = 0.04970, t = -2.083
paired t-test -- training 3, fly delta, bucket #1 vs. #5:
  n = 19, means: 0.241, 0.212; t-test: p = 0.41689, t = 0.831

writing imgs/reward_pi_post__3_min_buckets.png...

number __calculated__ rewards by post bucket:
paired t-test -- training 1, exp fly trn. last 3 min vs. exp fly post 1st 3 min:
  n = 27, means: 23.9, 11.7; t-test: p = 0.00000, t = 7.758
paired t-test -- training 1, yok fly trn. last 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 9, 6.05; t-test: p = 0.02677, t = 2.382
paired t-test -- training 1, exp fly trn. last 3 min vs. yok fly trn. last 3 min:
  n = 22, means: 24.8, 9; t-test: p = 0.00012, t = 4.691
paired t-test -- training 1, exp fly post 1st 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 11.6, 6.05; t-test: p = 0.04773, t = 2.103
paired t-test -- training 1, exp fly post 2nd 3 min vs. yok fly post 2nd 3 min:
  n = 22, means: 7.86, 5.64; t-test: p = 0.35791, t = 0.940
paired t-test -- training 1, exp fly post 3rd 3 min vs. yok fly post 3rd 3 min:
  n = 22, means: 7.18, 4.59; t-test: p = 0.24746, t = 1.190
paired t-test -- training 2, exp fly trn. last 3 min vs. exp fly post 1st 3 min:
  n = 27, means: 21.8, 10.2; t-test: p = 0.00000, t = 8.069
paired t-test -- training 2, yok fly trn. last 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 11.2, 7.09; t-test: p = 0.00060, t = 4.030
paired t-test -- training 2, exp fly trn. last 3 min vs. yok fly trn. last 3 min:
  n = 22, means: 20.6, 11.2; t-test: p = 0.00927, t = 2.865
paired t-test -- training 2, exp fly post 1st 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 9.41, 7.09; t-test: p = 0.33711, t = 0.982
paired t-test -- training 2, exp fly post 2nd 3 min vs. yok fly post 2nd 3 min:
  n = 22, means: 6.73, 5.18; t-test: p = 0.35803, t = 0.940
paired t-test -- training 2, exp fly post 3rd 3 min vs. yok fly post 3rd 3 min:
  n = 22, means: 7.36, 5.55; t-test: p = 0.23180, t = 1.231
paired t-test -- training 3, exp fly trn. last 3 min vs. exp fly post 1st 3 min:
  n = 27, means: 20.8, 8.59; t-test: p = 0.00000, t = 6.322
paired t-test -- training 3, yok fly trn. last 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 8.86, 5.86; t-test: p = 0.04089, t = 2.179
paired t-test -- training 3, exp fly trn. last 3 min vs. yok fly trn. last 3 min:
  n = 22, means: 20.5, 8.86; t-test: p = 0.00417, t = 3.214
paired t-test -- training 3, exp fly post 1st 3 min vs. yok fly post 1st 3 min:
  n = 22, means: 9.23, 5.86; t-test: p = 0.05651, t = 2.018
paired t-test -- training 3, exp fly post 2nd 3 min vs. yok fly post 2nd 3 min:
  n = 22, means: 6.82, 5.59; t-test: p = 0.49187, t = 0.700
paired t-test -- training 3, exp fly post 3rd 3 min vs. yok fly post 3rd 3 min:
  n = 22, means: 6.64, 4.45; t-test: p = 0.15083, t = 1.491

writing imgs/rewards__3_min_buckets.png...

average RDP line length (epsilon 0.0)
skipped

average distance traveled between actual rewards by sync bucket:
paired t-test -- training 1, bucket #1 vs. #5:
  n = 27, means: 382, 329; t-test: p = 0.13492, t = 1.543
paired t-test -- training 2, bucket #1 vs. #5:
  n = 27, means: 343, 291; t-test: p = 0.01705, t = 2.549
paired t-test -- training 3, bucket #1 vs. #5:
  n = 27, means: 300, 314; t-test: p = 0.55219, t = -0.602

average speed bottom [mm/s]:
paired t-test -- training 1, exp fly training vs. yok fly training:
  n = 22, means: 4.92, 4.16; t-test: p = 0.10379, t = 1.701
paired t-test -- training 2, exp fly training vs. yok fly training:
  n = 22, means: 5.25, 4.85; t-test: p = 0.44344, t = 0.781
paired t-test -- training 3, exp fly training vs. yok fly training:
  n = 22, means: 4.65, 4.55; t-test: p = 0.84024, t = 0.204
means with 95% confidence intervals (pre, training):
note: sidewall and lid currently included
  n = 27  (in "()" below if different)
  t1, exp fly: 3.59 ±0.52, 4.93 ±0.47
      yok fly: 2.93 ±0.61 (22), 4.16 ±0.66 (22)
  t2, exp fly: 4.84 ±0.52, 5.02 ±0.63
      yok fly: 4.51 ±0.77 (22), 4.85 ±0.80 (22)
  t3, exp fly: 5.38 ±0.66, 4.41 ±0.69
      yok fly: 4.98 ±0.93 (22), 4.55 ±0.70 (22)

average stop fraction:
paired t-test -- training 1, exp fly training vs. yok fly training:
  n = 22, means: 0.407, 0.45; t-test: p = 0.34027, t = -0.976
paired t-test -- training 2, exp fly training vs. yok fly training:
  n = 22, means: 0.364, 0.39; t-test: p = 0.57551, t = -0.569
paired t-test -- training 3, exp fly training vs. yok fly training:
  n = 22, means: 0.41, 0.416; t-test: p = 0.90371, t = -0.122
means with 95% confidence intervals (pre, training):
  n = 27  (in "()" below if different)
  t1, exp fly: 47.5% ±6.7%, 40.2% ±3.7%
      yok fly: 57.2% ±9.0% (22), 45.0% ±7.3% (22)
  t2, exp fly: 37.4% ±5.4%, 37.4% ±3.0%
      yok fly: 41.6% ±8.3% (22), 39.0% ±7.9% (22)
  t3, exp fly: 32.6% ±4.5%, 42.2% ±4.3%
      yok fly: 39.1% ±9.4% (22), 41.6% ±8.0% (22)

rewards per minute:
means with 95% confidence intervals:
  n = 27  (in "()" below if different)
  t1, exp fly: 7.3 ±1.5
  t2, exp fly: 7.8 ±1.4
  t3, exp fly: 7.3 ±1.3

writing imgs/dist_btwn_rewards__10_min_buckets.png...
distance from trajectory COM to reward circle center
writing imgs/com_reward_distance.png...
Saved COM-distance plot to imgs/com_reward_distance.png
writing imgs/com_reward_distance__exp_minus_yoked.png...
Saved COM-distance (exp − yoked) plot to imgs/com_reward_distance__exp_minus_yoked.png
writing imgs/com_reward_distance__exp_only.png...
Saved COM-distance plot to imgs/com_reward_distance__exp_only.png

writing imgs/rewards_per_dist__10_min_buckets.png...

writing imgs/reward_pi_diff__10_min_buckets.png...

writing imgs/reward_pi_post_diff__3_min_buckets.png...

writing learning_stats.csv...
writing imgs/analysis.png...
writing imgs/post_rewards_fly_1.png...
writing imgs/ctrl_rewards_fly_1.png...
writing imgs/post_rewards_fly_2.png...
writing imgs/ctrl_rewards_fly_2.png...
